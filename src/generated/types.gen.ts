// This file is auto-generated by @hey-api/openapi-ts

export type AgeClassificationInput = {
  /**
   * An optional model to use for age classification. If not provided, the default model will determined by the worker
   */
  model?: string | null;
  /**
   * The URL of the media to classify. This can either be a URL to an image or a video or a ZIP containing multiple images
   */
  mediaUrl: string;
};

export type AgeClassificationOutput = {
  labels: {
    [key: string]: Array<AgeClassifierLabel>;
  };
  hasMinor: boolean;
  prediction: AgeClassificationPrediction;
};

export const AgeClassificationPrediction = {
  PASS: 'pass',
  FAIL: 'fail',
} as const;

export type AgeClassificationPrediction =
  (typeof AgeClassificationPrediction)[keyof typeof AgeClassificationPrediction];

/**
 * Age classification
 */
export type AgeClassificationStep = WorkflowStep & {
  $type: 'ageClassification';
} & {
  input: AgeClassificationInput;
  output?: AgeClassificationOutput;
} & {
  $type: 'ageClassification';
};

/**
 * Age classification
 */
export type AgeClassificationStepTemplate = WorkflowStepTemplate & {
  $type: 'ageClassification';
} & {
  input: AgeClassificationInput;
} & {
  $type: 'ageClassification';
};

export type AgeClassifierLabel = {
  age: string;
  isMinor: boolean;
  boundingBox: Array<number>;
};

export type BatchOcrSafetyClassificationInput = {
  mediaUrls: Array<string>;
};

export type BatchOcrSafetyClassificationOutput = {
  results: Array<BatchOcrSafetyClassificationResult>;
};

export type BatchOcrSafetyClassificationResult = {
  mediaUrl: string;
  classification: string;
  text?: string | null;
};

/**
 * Represents a blob that gets produced as part of a specific job
 */
export type Blob = {
  type: string;
  /**
   * Gets the id of the blob that contains this image.
   */
  id: string;
  /**
   * Gets a value indicating whether the blob is available.
   */
  available: boolean;
  /**
   * Gets a url that can be used to preview the blob.
   */
  url?: string | null;
  /**
   * Get when the url is set to expire
   */
  urlExpiresAt?: string | null;
  /**
   * Get the id of the job that is associated with this blob.
   */
  jobId?: string | null;
  nsfwLevel?: NsfwLevel;
  /**
   * Get an optional reason for why the blob was blocked. This is only set if the blob was blocked.
   */
  blockedReason?: string | null;
};

export const BuzzClientAccount = {
  USER: 'user',
  GENERATION: 'generation',
} as const;

export type BuzzClientAccount = (typeof BuzzClientAccount)[keyof typeof BuzzClientAccount];

export type ComfyInput = {
  /**
   * Get the comfy workflow that needs to be executed
   */
  comfyWorkflow: {
    [key: string]: ComfyNode;
  };
  /**
   * The number of jobs to start with this workflow.
   */
  quantity?: number;
  /**
   * External metadata that will be stored with the image
   */
  imageMetadata?: string | null;
  /**
   * Opt-into using the spine controller exclusively
   */
  useSpineComfy?: boolean | null;
};

export type ComfyNode = {
  classType: string;
  meta?: {
    [key: string]: string;
  } | null;
  isChanged?: string | null;
  inputs: {
    [key: string]: string | number | boolean | [number, number];
  };
};

export type ComfyOutput = {
  /**
   * Get a list of blobs that got generated by this comfy workflow step.
   */
  blobs?: Array<Blob>;
};

/**
 * Comfy workflows
 */
export type ComfyStep = WorkflowStep & {
  $type: 'comfy';
} & {
  input: ComfyInput;
  output?: ComfyOutput;
} & {
  $type: 'comfy';
};

/**
 * Comfy workflows
 */
export type ComfyStepTemplate = WorkflowStepTemplate & {
  $type: 'comfy';
} & {
  input: ComfyInput;
} & {
  $type: 'comfy';
};

export const ContainerFormat = {
  MP4: 'mp4',
  WEB_M: 'webM',
} as const;

export type ContainerFormat = (typeof ContainerFormat)[keyof typeof ContainerFormat];

export type CursedArrayOfTelemetryCursorAndWorkflow = {
  next: string;
  items: Array<Workflow>;
};

/**
 * Represents the input information needed for the Echo workflow step.
 */
export type EchoInput = {
  /**
   * The message to be returned in the output.
   */
  message: string;
};

/**
 * Represents the output information returned from the Echo workflow step.
 */
export type EchoOutput = {
  /**
   * The message to be returned.
   */
  message: string;
};

/**
 * Echo
 */
export type EchoStep = WorkflowStep & {
  $type: 'echo';
} & {
  input: EchoInput;
  output?: EchoOutput;
} & {
  $type: 'echo';
};

/**
 * Echo
 */
export type EchoStepTemplate = WorkflowStepTemplate & {
  $type: 'echo';
} & {
  input: EchoInput;
} & {
  $type: 'echo';
};

/**
 * An epock result.
 */
export type EpochResult = {
  epochNumber?: number;
  /**
   * Get the name of the generated epoch assets
   */
  blobName: string;
  /**
   * Get the total size in bytes of the asset
   */
  blobSize?: number | null;
  /**
   * Get a list of the names of the blobs that represent sample images
   */
  sampleImages?: Array<string>;
  /**
   * A presigned url that points to the epoch file
   */
  blobUrl: string;
};

export const FileFormat = {
  UNKNOWN: 'unknown',
  SAFE_TENSOR: 'safeTensor',
  PICKLE_TENSOR: 'pickleTensor',
  DIFFUSERS: 'diffusers',
  CORE_ML: 'coreML',
  ONNX: 'onnx',
} as const;

export type FileFormat = (typeof FileFormat)[keyof typeof FileFormat];

export type Flux1KontextDevImageGenInput = Flux1KontextImageGenInput & {
  readonly model: string;
} & {
  model: 'dev';
};

export type Flux1KontextImageGenInput = ImageGenInput & {
  engine: 'flux1-kontext';
} & {
  readonly model: string;
  prompt: string;
  images?: Array<string>;
  aspectRatio?: '21:9' | '16:9' | '4:3' | '3:2' | '1:1' | '2:3' | '3:4' | '9:16' | '9:21';
  outputFormat?: 'jpeg' | 'png';
  guidanceScale?: number;
  quantity?: number;
  seed?: number | null;
} & {
  engine: 'flux1-kontext';
};

export type Flux1KontextMaxImageGenInput = Flux1KontextImageGenInput & {
  readonly model: string;
} & {
  model: 'max';
};

export type Flux1KontextProImageGenInput = Flux1KontextImageGenInput & {
  readonly model: string;
} & {
  model: 'pro';
};

export type FluxDevFastImageResourceTrainingInput = ImageResourceTrainingInput & {
  engine: 'flux-dev-fast';
} & {} & {
  engine: 'flux-dev-fast';
};

export type GoogleImageGenInput = ImageGenInput & {
  engine: 'google';
} & {
  model: string;
  prompt: string;
} & {
  engine: 'google';
};

export const HaiperVideoGenAspectRatio = {
  '16:9': '16:9',
  '4:3': '4:3',
  '1:1': '1:1',
  '9:16': '9:16',
  '3:4': '3:4',
} as const;

export type HaiperVideoGenAspectRatio =
  (typeof HaiperVideoGenAspectRatio)[keyof typeof HaiperVideoGenAspectRatio];

export const HaiperVideoGenCameraMovement = {
  NONE: 'none',
  PAN_RIGHT: 'panRight',
  PAN_LEFT: 'panLeft',
  TILT_UP: 'tiltUp',
  TILT_DOWN: 'tiltDown',
  ZOOM_IN: 'zoomIn',
  ZOOM_OUT: 'zoomOut',
} as const;

export type HaiperVideoGenCameraMovement =
  (typeof HaiperVideoGenCameraMovement)[keyof typeof HaiperVideoGenCameraMovement];

export type HaiperVideoGenInput = VideoGenInput & {
  engine: 'haiper';
} & {
  negativePrompt?: string | null;
  cameraMovement?: HaiperVideoGenCameraMovement;
  seed?: number;
  duration?: 2 | 4 | 8;
  aspectRatio?: HaiperVideoGenAspectRatio;
  model?: HaiperVideoGenModel;
  resolution?: 720 | 1080 | 2160;
  enablePromptEnhancer?: boolean;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
} & {
  engine: 'haiper';
};

export const HaiperVideoGenModel = {
  V1_5: 'v1_5',
  V2: 'v2',
} as const;

export type HaiperVideoGenModel = (typeof HaiperVideoGenModel)[keyof typeof HaiperVideoGenModel];

export type HaiperVideoGenOutput = VideoGenOutput & {
  progress?: number | null;
  externalTOSViolation?: boolean | null;
  message?: string | null;
};

export const HumanoidImageMaskCategory = {
  DRESSES: 'dresses',
  UPPER_BODY: 'upperBody',
  LOWER_BODY: 'lowerBody',
} as const;

export type HumanoidImageMaskCategory =
  (typeof HumanoidImageMaskCategory)[keyof typeof HumanoidImageMaskCategory];

export type HumanoidImageMaskInput = {
  imageUrl: string;
  category: HumanoidImageMaskCategory;
};

export type HumanoidImageMaskOutput = {
  blob: Blob;
};

export type HunyuanVdeoGenInput = VideoGenInput & {
  engine: 'hunyuan';
} & {
  cfgScale?: number;
  frameRate?: number;
  duration?: number;
  seed?: number | null;
  steps?: number;
  width?: number;
  height?: number;
  loras?: Array<VideoGenInputLora>;
  model?: string | null;
} & {
  engine: 'hunyuan';
};

export type ImageBlob = Blob & {
  type: 'image';
} & {
  width?: number | null;
  height?: number | null;
} & {
  type: 'image';
};

export type ImageGenInput = {
  engine: string;
};

export type ImageGenInputLora = {
  air: string;
  strength?: number;
};

export type ImageGenOutput = {
  /**
   * A collection of output images.
   */
  images: Array<ImageBlob>;
};

/**
 * Image Generation
 */
export type ImageGenStep = WorkflowStep & {
  $type: 'imageGen';
} & {
  input: ImageGenInput;
  output?: ImageGenOutput;
} & {
  $type: 'imageGen';
};

/**
 * Image Generation
 */
export type ImageGenStepTemplate = WorkflowStepTemplate & {
  $type: 'imageGen';
} & {
  input: ImageGenInput;
} & {
  $type: 'imageGen';
};

/**
 * Information for a controlnet provided for a text to image input.
 */
export type ImageJobControlNet = {
  preprocessor?: ImageTransformer;
  /**
   * A value representing the weight applied to the ControlNet.
   */
  weight?: number;
  /**
   * A value representing the start step selected for the ControlNet.
   */
  startStep?: number;
  /**
   * A value representing the end step selected for the ControlNet.
   */
  endStep?: number;
};

export type ImageJobNetworkParams = {
  /**
   * In case of Lora and LoCon, set the strength of the network
   */
  strength?: number | null;
  /**
   * In case of a TextualInversion, set the trigger word of the network
   */
  triggerWord?: string | null;
  /**
   * A legacy type set by the consumer
   */
  type?: string | null;
};

export const ImageResouceTrainingModerationStatus = {
  EVALUATING: 'evaluating',
  UNDER_REVIEW: 'underReview',
  APPROVED: 'approved',
  REJECTED: 'rejected',
} as const;

export type ImageResouceTrainingModerationStatus =
  (typeof ImageResouceTrainingModerationStatus)[keyof typeof ImageResouceTrainingModerationStatus];

/**
 * Input for an image resource training step.
 */
export type ImageResourceTrainingInput = {
  engine: string;
  /**
   * The primary model to train upon.
   */
  model: string;
  /**
   * A url referring data to use in training.
   */
  trainingData: string;
  /**
   * The number of images embedded in this training data. This is used to calculate the cost of training.
   */
  trainingDataImagesCount: number;
  /**
   * The desired lora name.
   */
  loraName?: string;
  /**
   * A selection of sample prompts.
   */
  samplePrompts?: Array<string>;
};

export type ImageResourceTrainingOutput = {
  moderationStatus: ImageResouceTrainingModerationStatus;
  /**
   * An array of epochs.
   */
  epochs: Array<EpochResult>;
  /**
   * The selected prompts for sample images
   */
  sampleImagesPrompts: Array<string>;
  /**
   * The selected images for sample images
   */
  sampleInputImages?: Array<string> | null;
  /**
   * Get wether the blobs are actually stored as assets
   * Assets are deprecated and require a different retrieval mechanism
   */
  storedAsAssets?: boolean | null;
  /**
   * Get an estimate in minutes on how long the work is expected to take
   */
  eta?: number | null;
};

/**
 * LORA Training
 */
export type ImageResourceTrainingStep = WorkflowStep & {
  $type: 'imageResourceTraining';
} & {
  input: ImageResourceTrainingInput;
  output?: ImageResourceTrainingOutput;
} & {
  $type: 'imageResourceTraining';
};

/**
 * LORA Training
 */
export type ImageResourceTrainingStepTemplate = WorkflowStepTemplate & {
  $type: 'imageResourceTraining';
} & {
  input: ImageResourceTrainingInput;
} & {
  $type: 'imageResourceTraining';
};

/**
 * Available image transformers.
 */
export const ImageTransformer = {
  CANNY: 'canny',
  DEPTH_ZOE: 'depthZoe',
  SOFTEDGE_PIDINET: 'softedgePidinet',
  REMBG: 'rembg',
} as const;

/**
 * Available image transformers.
 */
export type ImageTransformer = (typeof ImageTransformer)[keyof typeof ImageTransformer];

export type ImageUploadOutput = {
  blob: Blob;
};

/**
 * Image upload
 */
export type ImageUploadStep = WorkflowStep & {
  $type: 'imageUpload';
} & {
  /**
   * The workflow's input.
   */
  input: string;
  output?: ImageUploadOutput;
} & {
  $type: 'imageUpload';
};

/**
 * Image upload
 */
export type ImageUploadStepTemplate = WorkflowStepTemplate & {
  $type: 'imageUpload';
} & {
  /**
   * Input for the ImageUploadStep step.
   */
  input: string | null;
} & {
  $type: 'imageUpload';
};

export type Imagen4ImageGenInput = GoogleImageGenInput & {
  prompt: string;
  negativePrompt?: string;
  aspectRatio?: '1:1' | '16:9' | '9:16' | '3:4' | '4:3';
  numImages?: number;
  seed?: number | null;
} & {
  model: 'imagen4';
};

/**
 * Available levels of job support.
 */
export const JobSupport = {
  UNSUPPORTED: 'unsupported',
  UNAVAILABLE: 'unavailable',
  AVAILABLE: 'available',
} as const;

/**
 * Available levels of job support.
 */
export type JobSupport = (typeof JobSupport)[keyof typeof JobSupport];

/**
 * Array of operations to perform
 */
export type JsonPatchDocument = Array<JsonPatchOperation>;

/**
 * Describes a single operation in a JSON Patch document. Includes the operation type, the target property path, and the value to be used.
 */
export type JsonPatchOperation = {
  /**
   * The operation type. Allowed values: 'add', 'remove', 'replace', 'move', 'copy', 'test'.
   */
  op: 'add' | 'remove' | 'replace' | 'move' | 'copy' | 'test';
  /**
   * The JSON Pointer path to the property in the target document where the operation is to be applied.
   */
  path: string;
  /**
   * Should be a path, required when using move, copy
   */
  from?: string;
  /**
   * The value to apply for 'add', 'replace', or 'test' operations. Not required for 'remove', 'move', or 'copy'.
   */
  value?:
    | string
    | number
    | boolean
    | {
        [key: string]: unknown;
      }
    | Array<unknown>
    | null;
};

export type KlingCameraControl = {
  config?: KlingCameraControlConfig;
};

export type KlingCameraControlConfig = {
  /**
   * Horizontal, controls the camera's movement along the horizontal axis (translation along the x-axis).
   */
  horizontal?: number | null;
  /**
   * Vertical, controls the camera's movement along the vertical axis (translation along the y-axis).
   */
  vertical?: number | null;
  /**
   * Pan, controls the camera's rotation in the horizontal plane (rotation around the y-axis).
   */
  pan?: number | null;
  /**
   * Tilt, controls the camera's rotation in the horizontal plane (rotation around the y-axis).
   */
  tilt?: number | null;
  /**
   * Roll, controls the camera's rolling amount (rotation around the z-axis).
   */
  roll?: number | null;
  /**
   * Zoom, controls the change in the camera's focal length, affecting the proximity of the field of view.
   */
  zoom?: number | null;
};

export const KlingMode = {
  STANDARD: 'standard',
  PROFESSIONAL: 'professional',
} as const;

export type KlingMode = (typeof KlingMode)[keyof typeof KlingMode];

export const KlingModel = {
  V1: 'v1',
  V1_5: 'v1_5',
  V1_6: 'v1_6',
  V2: 'v2',
} as const;

export type KlingModel = (typeof KlingModel)[keyof typeof KlingModel];

export const KlingVideoGenAspectRatio = {
  '16:9': '16:9',
  '9:16': '9:16',
  '1:1': '1:1',
} as const;

export type KlingVideoGenAspectRatio =
  (typeof KlingVideoGenAspectRatio)[keyof typeof KlingVideoGenAspectRatio];

export const KlingVideoGenDuration = {
  5: '5',
  10: '10',
} as const;

export type KlingVideoGenDuration =
  (typeof KlingVideoGenDuration)[keyof typeof KlingVideoGenDuration];

export type KlingVideoGenInput = VideoGenInput & {
  engine: 'kling';
} & {
  model?: KlingModel;
  negativePrompt?: string | null;
  cfgScale?: number;
  mode?: KlingMode;
  aspectRatio?: KlingVideoGenAspectRatio;
  duration?: KlingVideoGenDuration;
  cameraControl?: KlingCameraControl;
  sourceImageUrl?: string | null;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
} & {
  engine: 'kling';
};

export type KohyaImageResourceTrainingInput = ImageResourceTrainingInput & {
  engine: 'kohya';
} & {
  /**
   * An epoch is one set of learning. By default, we will save a maximum of 20 epochs (evenly distributed), and they are all available for download.
   */
  maxTrainEpochs?: number;
  /**
   * Num Repeats defines how many times each individual image gets put into VRAM. As opposed to batch size, which is how many images are placed into VRAM at once.
   */
  numRepeats?: number;
  /**
   * Batch size is the number of images that will be placed into VRAM at once. A batch size of 2 will train two images at a time, simultaneously.
   */
  trainBatchSize?: number | null;
  /**
   * Specify the maximum resolution of training images. If the training images exceed the resolution specified here, they will be scaled down to this resolution
   */
  resolution?: number | null;
  /**
   * Sorts images into buckets by size for the purposes of training. If your training images are all the same size, you can turn this option off, but leaving it on has no effect.
   */
  enableBucket?: boolean;
  /**
   * Randomly changes the order of your tags during training. The intent of shuffling is to improve learning. If you are using captions (sentences), this option has no meaning.
   */
  shuffleCaption?: boolean;
  /**
   * If your training images have tags, you can randomly shuffle them.
   * However, if you have words that you want to keep at the beginning, you can use this option to specify "Keep the first 0 words at the beginning".
   * This option does nothing if the Shuffle Tags option is off.
   */
  keepTokens?: number;
  /**
   * Determines which layer's vector output will be used. There are 12 layers, and setting the skip will select "xth from the end" of the total layers. For anime, we use 2. For everything else, 1.
   */
  clipSkip?: number;
  /**
   * If this option is turned on, the image will be horizontally flipped randomly. It can learn left and right angles, which is useful when you want to learn symmetrical people and objects.
   */
  flipAugmentation?: boolean;
  /**
   * Sets the learning rate for U-Net. This is the learning rate when performing additional learning on each attention block (and other blocks depending on the setting) in U-Net
   */
  unetLR?: number;
  /**
   * Sets the learning rate for the text encoder. The effect of additional training on text encoders affects the entire U-Net.
   */
  textEncoderLR?: number;
  /**
   * You can change the learning rate in the middle of learning. A scheduler is a setting for how to change the learning rate.
   */
  lrScheduler?: 'constant' | 'cosine' | 'cosine_with_restarts' | 'linear';
  /**
   * This option specifies how many cycles the scheduler runs during training. It is only used when "cosine_with_restarts" or "polynomial" is used as the scheduler.
   */
  lrSchedulerNumCycles?: number;
  /**
   * Learning is performed by putting noise of various strengths on the training image,
   * but depending on the difference in strength of the noise on which it is placed, learning will be
   * stable by moving closer to or farther from the learning target.
   *
   * Min SNR gamma was introduced to compensate for that. When learning images have little noise,
   * it may deviate greatly from the target, so try to suppress this jump.
   */
  minSnrGamma?: number | null;
  /**
   * The larger the Dim setting, the more learning information can be stored, but the possibility of learning unnecessary information other than the learning target increases. A larger Dim also increases LoRA file size.
   */
  networkDim?: number | null;
  /**
   * The smaller the Network alpha value, the larger the stored LoRA neural net weights.
   * For example, with an Alpha of 16 and a Dim of 32, the strength of the weight used is 16/32 = 0.5,
   * meaning that the learning rate is only half as powerful as the Learning Rate setting.
   *
   * If Alpha and Dim are the same number, the strength used will be 1 and will have no effect on the learning rate.
   */
  networkAlpha?: number | null;
  /**
   * Adds noise to training images. 0 adds no noise at all. A value of 1 adds strong noise.
   */
  noiseOffset?: number | null;
  /**
   * The optimizer determines how to update the neural net weights during training.
   * Various methods have been proposed for smart learning, but the most commonly used in LoRA learning
   * is "AdamW8bit" or "Adafactor" for SDXL.
   */
  optimizerType?: string | null;
  readonly targetSteps?: number | null;
} & {
  engine: 'kohya';
};

export const LightricksAspectRatio = {
  '1:1': '1:1',
  '16:9': '16:9',
  '9:16': '9:16',
  '3:2': '3:2',
  '2:3': '2:3',
} as const;

export type LightricksAspectRatio =
  (typeof LightricksAspectRatio)[keyof typeof LightricksAspectRatio];

export type LightricksVideoGenInput = VideoGenInput & {
  engine: 'lightricks';
} & {
  negativePrompt?: string | null;
  cfgScale?: number;
  frameRate?: number;
  duration?: number;
  seed?: number | null;
  steps?: number;
  aspectRatio?: LightricksAspectRatio;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
  expandPrompt?: boolean;
} & {
  engine: 'lightricks';
};

export type MiniMaxVideoGenInput = VideoGenInput & {
  engine: 'minimax';
} & {
  model?: MiniMaxVideoGenModel;
  enablePromptEnhancer?: boolean;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
} & {
  engine: 'minimax';
};

export const MiniMaxVideoGenModel = {
  HAILOU: 'hailou',
} as const;

export type MiniMaxVideoGenModel = (typeof MiniMaxVideoGenModel)[keyof typeof MiniMaxVideoGenModel];

export type MochiVideoGenInput = VideoGenInput & {
  engine: 'mochi';
} & {
  seed?: number;
  enablePromptEnhancer?: boolean;
} & {
  engine: 'mochi';
};

export type MusubiImageResourceTrainingInput = ImageResourceTrainingInput & {
  engine: 'musubi';
} & {
  /**
   * An epoch is one set of learning. By default, we will save a maximum of 20 epochs (evenly distributed), and they are all available for download.
   */
  maxTrainEpochs?: number;
  /**
   * Num Repeats defines how many times each individual image gets put into VRAM. As opposed to batch size, which is how many images are placed into VRAM at once.
   */
  numRepeats?: number;
  /**
   * Batch size is the number of images that will be placed into VRAM at once. A batch size of 2 will train two images at a time, simultaneously.
   */
  trainBatchSize?: number | null;
  /**
   * Specify the maximum resolution of training images. If the training images exceed the resolution specified here, they will be scaled down to this resolution
   */
  resolution?: number | null;
  /**
   * Sorts images into buckets by size for the purposes of training. If your training images are all the same size, you can turn this option off, but leaving it on has no effect.
   */
  enableBucket?: boolean;
  /**
   * Sets the learning rate for U-Net. This is the learning rate when performing additional learning on each attention block (and other blocks depending on the setting) in U-Net
   */
  unetLR?: number;
  /**
   * You can change the learning rate in the middle of learning. A scheduler is a setting for how to change the learning rate.
   */
  lrScheduler?: 'constant' | 'cosine' | 'cosine_with_restarts' | 'linear';
  /**
   * This option specifies how many cycles the scheduler runs during training. It is only used when "cosine_with_restarts" or "polynomial" is used as the scheduler.
   */
  lrSchedulerNumCycles?: number;
  /**
   * The larger the Dim setting, the more learning information can be stored, but the possibility of learning unnecessary information other than the learning target increases. A larger Dim also increases LoRA file size.
   */
  networkDim?: number | null;
  /**
   * The smaller the Network alpha value, the larger the stored LoRA neural net weights.
   * For example, with an Alpha of 16 and a Dim of 32, the strength of the weight used is 16/32 = 0.5,
   * meaning that the learning rate is only half as powerful as the Learning Rate setting.
   *
   * If Alpha and Dim are the same number, the strength used will be 1 and will have no effect on the learning rate.
   */
  networkAlpha?: number | null;
  /**
   * The optimizer determines how to update the neural net weights during training.
   * Various methods have been proposed for smart learning, but the most commonly used in LoRA learning
   * is "AdamW8bit" or "Adafactor" for SDXL.
   */
  optimizerType?: string | null;
  readonly targetSteps?: number | null;
} & {
  engine: 'musubi';
};

export const NsfwLevel = {
  PG: 'pg',
  P_G13: 'pG13',
  R: 'r',
  X: 'x',
  XXX: 'xxx',
  NA: 'na',
} as const;

export type NsfwLevel = (typeof NsfwLevel)[keyof typeof NsfwLevel];

export type OpenAiDallE2CreateImageGenInput = OpenAiDallE2ImageGenInput & {
  background?: 'auto' | 'transparent' | 'opaque';
} & {
  operation: 'createImage';
};

export type OpenAiDallE2EditImageInput = OpenAiDallE2ImageGenInput & {
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  image: string;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  mask?: string | null;
} & {
  operation: 'editImage';
};

export type OpenAiDallE2ImageGenInput = OpenApiImageGenInput & {
  operation: string;
  prompt: string;
  size: '256x256' | '512x512' | '1024x1024';
  quantity?: number;
} & {
  model: 'dall-e-2';
};

export type OpenAiDallE3CreateImageGenInput = OpenAiDallE3ImageGenInput & {
  background?: 'auto' | 'transparent' | 'opaque';
} & {
  operation: 'createImage';
};

export type OpenAiDallE3ImageGenInput = OpenApiImageGenInput & {
  operation: string;
  prompt: string;
  size: '1024x1024' | '1792x1024' | '1024x1792';
  style?: 'natural' | 'vivid';
  quality?: 'auto' | 'hd' | 'standard';
} & {
  model: 'dall-e-3';
};

export type OpenAiGpt1CreateImageInput = OpenAiGpt1ImageGenInput & {} & {
  operation: 'createImage';
};

export type OpenAiGpt1EditImageInput = OpenAiGpt1ImageGenInput & {
  images: Array<string>;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  mask?: string | null;
} & {
  operation: 'editImage';
};

export type OpenAiGpt1ImageGenInput = OpenApiImageGenInput & {
  operation: string;
  prompt: string;
  size?: '1024x1024' | '1536x1024' | '1024x1536';
  quantity?: number;
  background?: 'auto' | 'transparent' | 'opaque';
  quality?: 'auto' | 'high' | 'medium' | 'low';
} & {
  model: 'gpt-image-1';
};

export type OpenApiImageGenInput = ImageGenInput & {
  engine: 'openai';
} & {
  model: string;
  prompt: string;
} & {
  engine: 'openai';
};

/**
 * Available options for priority.
 */
export const Priority = {
  HIGH: 'high',
  NORMAL: 'normal',
  LOW: 'low',
} as const;

/**
 * Available options for priority.
 */
export type Priority = (typeof Priority)[keyof typeof Priority];

export type ProblemDetails = {
  type?: string | null;
  title?: string | null;
  status?: number | null;
  detail?: string | null;
  instance?: string | null;
  [key: string]:
    | unknown
    | (string | null)
    | (string | null)
    | (number | null)
    | (string | null)
    | (string | null)
    | undefined;
};

/**
 * Details for a specific resource.
 */
export type ResourceInfo = {
  /**
   * An AIR ID for the resource.
   */
  air: string;
  /**
   * The resource size in bytes.
   */
  size: number;
  /**
   * A collection of hashes.
   */
  hashes: {
    [key: string]: string;
  };
  /**
   * An array of download urls.
   */
  downloadUrls: Array<string>;
  /**
   * The name of the resource.
   */
  resourceName?: string | null;
  /**
   * The name of the version.
   */
  versionName?: string | null;
  /**
   * The date time to invalidate at.
   */
  invalidateAt?: string | null;
  /**
   * A DateTime representing when early access for the resource ends.
   */
  earlyAccessEndsAt?: string | null;
  /**
   * A bool indicating if permission is required to use this resource.
   */
  checkPermission?: boolean;
  /**
   * A bool indicating if generation is enabled for this resource.
   */
  canGenerate?: boolean;
  /**
   * An optional limit on the number of uses for this resource per user that has early acccess.
   */
  freeTrialLimit?: number | null;
  /**
   * Wether this resource requires authorization.
   */
  requiresAuthorization?: boolean | null;
  fileFormat?: FileFormat;
  /**
   * A boolean indicating whether this resource restricts mature content generation.
   * If resources with this restriction are used in generation, then generations will automatically be enforced to not generate mature content
   */
  hasMatureContentRestriction?: boolean;
  /**
   * Get a rank between 0-1 on the popularity of the resource.
   */
  popularityRank?: number | null;
  /**
   * Get wether this resource is featured
   */
  isFeatured?: boolean | null;
  /**
   * The date at which this model got published
   */
  publishedAt?: string | null;
  /**
   * A boolean indicating whether this resource restricts to SFW content generation.
   * NSFWContent covers X and AA whereas MatureContent includes R rated content.
   */
  hasNSFWContentRestriction?: boolean;
};

/**
 * The available options for schedulers used in image generation.
 */
export const Scheduler = {
  EULER_A: 'eulerA',
  EULER: 'euler',
  LMS: 'lms',
  HEUN: 'heun',
  DP_M2: 'dpM2',
  DP_M2A: 'dpM2A',
  DP_M2SA: 'dpM2SA',
  DP_M2M: 'dpM2M',
  DPMSDE: 'dpmsde',
  DPM_FAST: 'dpmFast',
  DPM_ADAPTIVE: 'dpmAdaptive',
  LMS_KARRAS: 'lmsKarras',
  DP_M2_KARRAS: 'dpM2Karras',
  DP_M2A_KARRAS: 'dpM2AKarras',
  DP_M2SA_KARRAS: 'dpM2SAKarras',
  DP_M2M_KARRAS: 'dpM2MKarras',
  DPMSDE_KARRAS: 'dpmsdeKarras',
  DDIM: 'ddim',
  PLMS: 'plms',
  UNI_PC: 'uniPC',
  UNDEFINED: 'undefined',
  LCM: 'lcm',
  DDPM: 'ddpm',
  DEIS: 'deis',
  DP_M3MSDE: 'dpM3MSDE',
} as const;

/**
 * The available options for schedulers used in image generation.
 */
export type Scheduler = (typeof Scheduler)[keyof typeof Scheduler];

/**
 * Input for an text to image step.
 */
export type TextToImageInput = {
  /**
   * The number of batches to run.
   */
  quantity?: number;
  /**
   * The size of each batch
   */
  batchSize?: number;
  /**
   * The AIR of the checkpoint model to use for generation.
   */
  model?: string;
  /**
   * Get or set a associative list of additional networks. Use the AIR of the network as the key.
   */
  additionalNetworks?: {
    [key: string]: ImageJobNetworkParams;
  };
  /**
   * Get or set a associative list of ControlNets.
   */
  controlNets?: Array<ImageJobControlNet>;
  /**
   * The provided text prompt.
   */
  prompt: string;
  /**
   * The provided negative text prompt.
   */
  negativePrompt?: string | null;
  scheduler?: Scheduler;
  /**
   * The number of steps for image generation.
   */
  steps?: number;
  /**
   * The CFG scale value for image generation.
   */
  cfgScale?: number;
  /**
   * The desired image width in pixels.
   */
  width: number;
  /**
   * The desired image height in pixels.
   */
  height: number;
  /**
   * The seed to use in image generation. Defaults to a random value if left unpopulated.
   */
  seed?: number;
  /**
   * The clip skip value for image generation.
   */
  clipSkip?: number;
  /**
   * External metadata that will be stored with the image
   */
  imageMetadata?: string | null;
  /**
   * An optional engine to use for generation.
   */
  engine?: string | null;
};

/**
 * Represents the output of a TextToImage workflow step.
 */
export type TextToImageOutput = {
  /**
   * A collection of output images.
   */
  images: Array<ImageBlob>;
};

/**
 * TextToImage
 */
export type TextToImageStep = WorkflowStep & {
  $type: 'textToImage';
} & {
  input: TextToImageInput;
  output?: TextToImageOutput;
} & {
  $type: 'textToImage';
};

/**
 * TextToImage
 */
export type TextToImageStepTemplate = WorkflowStepTemplate & {
  $type: 'textToImage';
} & {
  input: TextToImageInput;
} & {
  $type: 'textToImage';
};

/**
 * Transaction information.
 */
export type TransactionInfo = {
  type: TransactionType;
  /**
   * The transaction amount.
   */
  amount: number;
  /**
   * The transaction ID.
   */
  id?: string | null;
  accountType?: BuzzClientAccount;
};

export type TransactionSummary = {
  /**
   * Get a list of individual transactions.
   */
  list?: Array<TransactionInfo>;
  /**
   * A boolean returned with whatif requests to indicate whether the user has nsufficient buzz to run a workflow.
   */
  insufficientBuzz?: boolean | null;
};

export const TransactionType = {
  DEBIT: 'debit',
  CREDIT: 'credit',
} as const;

export type TransactionType = (typeof TransactionType)[keyof typeof TransactionType];

export type TranscodeInput = {
  sourceUrl: string;
  containerFormat?: ContainerFormat;
  width?: number;
  destinationUrl?: string | null;
};

export type TranscodeOutput = {
  /**
   * Gets the id of the blob that contains the media.
   */
  id: string;
  /**
   * Gets a value indicating whether the media is available.
   */
  available: boolean;
  /**
   * Gets a url that can be used to preview the media.
   */
  url?: string | null;
  /**
   * Get when the url is set to expire
   */
  urlExpiresAt?: string | null;
  /**
   * Get the id of the job that is associated with this media.
   */
  jobId: string;
};

/**
 * Transcoding
 */
export type TranscodeStep = WorkflowStep & {
  $type: 'transcode';
} & {
  input: TranscodeInput;
  output?: TranscodeOutput;
} & {
  $type: 'transcode';
};

export type TryOnUInput = {
  subjectUrl: string;
  garmentUrl: string;
  subjectMaskUrl?: string;
  subjectMaskBlobKey?: string;
  garmentDescription?: string;
  maskSubject?: boolean;
  cropSubject?: boolean;
  steps?: number;
  seed?: number;
};

export type TryOnUOutput = {
  blob: Blob;
};

/**
 * An request for updating a workflow.
 */
export type UpdateWorkflowRequest = {
  status?: UpdateWorkflowStatus;
  /**
   * An optional set of new properties to set on the workflow.
   */
  metadata?: {
    [key: string]: unknown;
  } | null;
  /**
   * An optional set of new tags to set on the workflow.
   */
  tags?: Array<string> | null;
  /**
   * Set to true to remove the mature content restriction on the workflow.
   */
  allowMatureContent?: boolean | null;
};

/**
 * Available statuses for updating workflows.
 */
export const UpdateWorkflowStatus = {
  CANCELED: 'canceled',
} as const;

/**
 * Available statuses for updating workflows.
 */
export type UpdateWorkflowStatus = (typeof UpdateWorkflowStatus)[keyof typeof UpdateWorkflowStatus];

export type UpdateWorkflowStepRequest = {
  /**
   * An set of new properties to set on the workflow step.
   */
  metadata: {
    [key: string]: unknown;
  };
};

export type ValidationProblemDetails = {
  type?: string | null;
  title?: string | null;
  status?: number | null;
  detail?: string | null;
  instance?: string | null;
  errors?: {
    [key: string]: Array<string>;
  };
  [key: string]:
    | unknown
    | (string | null)
    | (string | null)
    | (number | null)
    | (string | null)
    | (string | null)
    | {
        [key: string]: Array<string>;
      }
    | undefined;
};

export type ValueTupleOfStringAndInt32 = {
  [key: string]: never;
};

export const Veo3AspectRatio = {
  '16:9': '16:9',
  '9:16': '9:16',
  '1:1': '1:1',
} as const;

export type Veo3AspectRatio = (typeof Veo3AspectRatio)[keyof typeof Veo3AspectRatio];

export type Veo3VideoGenInput = VideoGenInput & {
  engine: 'veo3';
} & {
  negativePrompt?: string | null;
  enablePromptEnhancer?: boolean;
  aspectRatio?: Veo3AspectRatio;
  duration?: number;
  generateAudio?: boolean;
  seed?: number | null;
  fastMode?: boolean;
  images?: Array<string>;
} & {
  engine: 'veo3';
};

export type VideoBlob = Blob & {
  type: 'video';
} & {
  width?: number | null;
  height?: number | null;
} & {
  type: 'video';
};

export type VideoEnhancementInput = {
  sourceUrl: string;
  upscaler?: VideoEnhancementInputUpscalerOptions;
  interpolation?: VideoEnhancementInputInterpolationOptions;
};

export type VideoEnhancementInputInterpolationOptions = {
  multiplier: number;
};

export type VideoEnhancementInputUpscalerOptions = {
  model?: string | null;
  width: number;
  height: number;
};

export type VideoEnhancementOutput = {
  video: VideoBlob;
};

/**
 * Upscale videos and/or interpolate frames
 */
export type VideoEnhancementStep = WorkflowStep & {
  $type: 'videoEnhancement';
} & {
  input: VideoEnhancementInput;
  output?: VideoEnhancementOutput;
} & {
  $type: 'videoEnhancement';
};

/**
 * Upscale videos and/or interpolate frames
 */
export type VideoEnhancementStepTemplate = WorkflowStepTemplate & {
  $type: 'videoEnhancement';
} & {
  input: VideoEnhancementInput;
} & {
  $type: 'videoEnhancement';
};

export type VideoGenInput = {
  engine: string;
  prompt: string;
};

export type VideoGenInputLora = {
  air: string;
  strength: number;
};

export type VideoGenOutput = {
  video?: VideoBlob;
};

/**
 * Video generation
 */
export type VideoGenStep = WorkflowStep & {
  $type: 'videoGen';
} & {
  input: VideoGenInput;
  output?: VideoGenOutput;
} & {
  $type: 'videoGen';
};

/**
 * Video generation
 */
export type VideoGenStepTemplate = WorkflowStepTemplate & {
  $type: 'videoGen';
} & {
  input: VideoGenInput;
} & {
  $type: 'videoGen';
};

export type ViduVideoGenInput = VideoGenInput & {
  engine: 'vidu';
} & {
  enablePromptEnhancer?: boolean;
  seed?: number | null;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
  style?: ViduVideoGenStyle;
  duration?: 4 | 8;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  endSourceImage?: string | null;
  model?: ViduVideoGenModel;
  aspectRatio?: '16:9' | '9:16' | '1:1';
  movementAmplitude?: 'auto' | 'small' | 'medium' | 'large';
  images?: Array<string>;
  enableBackgroundMusic?: boolean;
} & {
  engine: 'vidu';
};

export const ViduVideoGenModel = {
  DEFAULT: 'default',
  Q1: 'q1',
} as const;

export type ViduVideoGenModel = (typeof ViduVideoGenModel)[keyof typeof ViduVideoGenModel];

export const ViduVideoGenStyle = {
  GENERAL: 'general',
  ANIME: 'anime',
} as const;

export type ViduVideoGenStyle = (typeof ViduVideoGenStyle)[keyof typeof ViduVideoGenStyle];

export type Wan21CivitaiVideoGenInput = Wan21VideoGenInput & {
  width?: number;
  height?: number;
  model?: string | null;
  images?: Array<string>;
} & {
  provider: 'civitai';
};

export type Wan21FalVideoGenInput = Wan21VideoGenInput & {
  aspectRatio?: '1:1' | '16:9' | '9:16';
  enablePromptExpansion?: boolean;
} & {
  provider: 'fal';
};

export type Wan21VideoGenInput = WanVideoGenInput & {
  provider: string | null;
} & {
  version: 'v2.1';
};

export type Wan225bFalImageGenInput = Wan225bImageGenInput & {} & {
  provider: 'fal';
};

export type Wan225bFalImageToVideoInput = Wan225bFalVideoGenInput & {
  images?: Array<string>;
} & {
  operation: 'image-to-video';
};

export type Wan225bFalTextToVideoInput = Wan225bFalVideoGenInput & {} & {
  operation: 'text-to-video';
};

export type Wan225bFalVideoGenInput = Wan225bVideoGenInput & {
  operation: string | null;
  resolution?: '480p' | '580p' | '720p';
  aspectRatio?: '1:1' | '16:9' | '9:16' | 'auto';
  enablePromptExpansion?: boolean;
  useDistill?: boolean;
  interpolatorModel?: 'none' | 'film' | 'rife';
  negativePrompt?: string | null;
  enableSafetyChecker?: boolean;
  numInferenceSteps?: number;
} & {
  provider: 'fal';
};

export type Wan225bImageGenInput = WanImageGenInput & {
  provider: string | null;
  steps?: number;
  shift?: number;
} & {
  version: 'v2.2-5b';
};

export type Wan225bVideoGenInput = WanVideoGenInput & {
  provider: string | null;
} & {
  version: 'v2.2-5b';
};

export type Wan22FalImageGenInput = Wan22ImageGenInput & {
  acceleration?: 'none' | 'fast' | 'faster';
} & {
  provider: 'fal';
};

export type Wan22FalImageToVideoInput = Wan22FalVideoGenInput & {
  images?: Array<string>;
} & {
  operation: 'image-to-video';
};

export type Wan22FalTextToVideoInput = Wan22FalVideoGenInput & {} & {
  operation: 'text-to-video';
};

export type Wan22FalVideoGenInput = Wan22VideoGenInput & {
  operation: string | null;
  resolution?: '480p' | '720p';
  aspectRatio?: '1:1' | '16:9' | '9:16' | '4:3' | '3:4' | '4:5' | '5:4';
  enablePromptExpansion?: boolean;
  shift?: number;
  interpolatorModel?: 'film' | 'rife';
  useTurbo?: boolean;
  negativePrompt?: string | null;
  enableSafetyChecker?: boolean;
} & {
  provider: 'fal';
};

export type Wan22ImageGenInput = WanImageGenInput & {
  provider: string | null;
  steps?: number;
} & {
  version: 'v2.2';
};

export type Wan22VideoGenInput = WanVideoGenInput & {
  provider: string | null;
} & {
  version: 'v2.2';
};

export type WanImageGenInput = ImageGenInput & {
  engine: 'wan';
} & {
  version: string | null;
  prompt: string;
  negativePrompt?: string | null;
  guidanceScale?: number;
  seed?: number | null;
  quantity?: number;
  imageSize?: string;
  enablePromptExpansion?: boolean;
  enableSafetyChecker?: boolean;
  loras?: Array<ImageGenInputLora>;
} & {
  engine: 'wan';
};

export type WanVideoGenInput = VideoGenInput & {
  engine: 'wan';
} & {
  version: string | null;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
  cfgScale?: number;
  frameRate?: number;
  duration?: number;
  seed?: number | null;
  steps?: number;
  loras?: Array<VideoGenInputLora>;
} & {
  engine: 'wan';
};

/**
 * Details of a workflow.
 */
export type Workflow = {
  /**
   * The ID for the workflow.
   */
  id?: string | null;
  /**
   * The date / time the workflow was created.
   */
  createdAt?: string;
  transactions?: TransactionSummary;
  /**
   * A collection of user defined metadata for the workflow.
   */
  metadata?: {
    [key: string]: unknown;
  };
  status?: WorkflowStatus;
  /**
   * The date / time the workflow was started. Null if not yet started.
   */
  startedAt?: string | null;
  /**
   * The date / time the workflow was completed. Null if not yet complete.
   */
  completedAt?: string | null;
  /**
   * An optional list of tags for the workflow.
   */
  tags?: Array<string>;
  /**
   * Get an associated collection of arguments
   */
  arguments?: {
    [key: string]: unknown;
  };
  /**
   * The steps for the workflow.
   */
  steps?: Array<WorkflowStep>;
  /**
   * An array of callback details for the workflow.
   */
  callbacks?: Array<WorkflowCallback>;
  tips?: WorkflowTips;
  cost?: WorkflowCost;
  nsfwLevel?: NsfwLevel;
  /**
   * Get or set whether this workflow is experimental
   */
  experimental?: boolean | null;
  /**
   * Gets or sets a value indicating whether mature content is allowed in this workflow.
   */
  allowMatureContent?: boolean | null;
  upgradeMode?: WorkflowUpgradeMode;
};

/**
 * Details of a callback setup for a workflow.
 */
export type WorkflowCallback = {
  /**
   * The url for the callback.
   */
  url: string;
  /**
   * An array of event types to send to the callback.
   */
  type: Array<
    | 'workflow:*'
    | 'workflow:unassigned'
    | 'workflow:processing'
    | 'workflow:succeeded'
    | 'workflow:failed'
    | 'workflow:expired'
    | 'workflow:canceled'
    | 'step:*'
    | 'step:unassigned'
    | 'step:processing'
    | 'step:succeeded'
    | 'step:failed'
    | 'step:expired'
    | 'step:canceled'
    | 'job:*'
    | 'job:unassigned'
    | 'job:processing'
    | 'job:succeeded'
    | 'job:failed'
    | 'job:expired'
    | 'job:canceled'
  >;
};

export type WorkflowCost = {
  /**
   * The base cost of this request, excludsing any tips
   */
  base?: number;
  /**
   * A breakdown of the cost factors for this request
   */
  factors?: {
    [key: string]: number;
  } | null;
  /**
   * A fixed set of cost additions for this request
   */
  fixed?: {
    [key: string]: number;
  } | null;
  tips?: WorkflowCostTips;
  /**
   * The total cost of this request, including tips
   */
  total?: number;
};

/**
 * Get the cost of tips
 */
export type WorkflowCostTips = {
  /**
   * The buzz tipped to Civitai
   */
  civitai: number;
  /**
   * The buzz tipped to the Creators who's resources were used
   */
  creators: number;
};

/**
 * Details of a workflow event.
 */
export type WorkflowEvent = {
  /**
   * The ID that represents the corresponding workflow.
   */
  workflowId: string;
  status: WorkflowStatus;
  /**
   * A timestamp for when this event got raised
   */
  timestamp?: string;
  $type?: string;
};

/**
 * Values available to represent workflow status.
 */
export const WorkflowStatus = {
  UNASSIGNED: 'unassigned',
  PREPARING: 'preparing',
  SCHEDULED: 'scheduled',
  PROCESSING: 'processing',
  SUCCEEDED: 'succeeded',
  FAILED: 'failed',
  EXPIRED: 'expired',
  CANCELED: 'canceled',
} as const;

/**
 * Values available to represent workflow status.
 */
export type WorkflowStatus = (typeof WorkflowStatus)[keyof typeof WorkflowStatus];

/**
 * Details of a workflow step.
 */
export type WorkflowStep = {
  $type: string;
  /**
   * The name of the workflow step. Used to allow steps to refer to one another.
   */
  name: string;
  priority?: Priority;
  /**
   * The maximum time to wait for this step to complete.
   */
  timeout?: string | null;
  /**
   * The maximum number of times this step should be retried.
   */
  retries?: number | null;
  /**
   * The jobs generated by this step.
   */
  jobs?: Array<WorkflowStepJob> | null;
  status?: WorkflowStatus;
  /**
   * The date / time the step was started. Null if not yet started.
   */
  startedAt?: string | null;
  /**
   * The date / time the step was completed. Null if not yet completed.
   */
  completedAt?: string | null;
  /**
   * A collection of user defined metadata for the workflow step.
   */
  metadata?: {
    [key: string]: unknown;
  };
  /**
   * An estimation on the current progression of this step, or null if there is no estimation
   */
  estimatedProgressRate?: number | null;
};

/**
 * Details of a workflow step event.
 */
export type WorkflowStepEvent = {
  /**
   * The workflow ID.
   */
  workflowId: string;
  /**
   * The workflow step's name.
   */
  stepName: string;
  status: WorkflowStatus;
  $type?: string;
};

/**
 * Details of a job produced by a workflow step.
 */
export type WorkflowStepJob = {
  /**
   * The job's ID.
   */
  id: string;
  status?: WorkflowStatus;
  /**
   * The date / time the job started. Null if not yet started.
   */
  startedAt?: string | null;
  /**
   * The date / time the job completed. Null if not yet completed.
   */
  completedAt?: string | null;
  queuePosition?: WorkflowStepJobQueuePosition;
  /**
   * The job's cost.
   */
  cost?: number;
  /**
   * An estimation on the current progression of this job, or null if there is no estimation
   */
  estimatedProgressRate?: number | null;
};

/**
 * Details of a workflow step job event.
 */
export type WorkflowStepJobEvent = {
  /**
   * The workflow ID.
   */
  workflowId: string;
  /**
   * The step's name.
   */
  stepName: string;
  /**
   * The job's ID.
   */
  jobId: string;
  status: WorkflowStatus;
  $type?: string;
  progress?: number | null;
  reason?: string | null;
  blockedReason?: string | null;
  matureContent?: boolean | null;
};

/**
 * Details of the workflow step job's queue position.
 */
export type WorkflowStepJobQueuePosition = {
  support: JobSupport;
  /**
   * The number of preceding jobs in the queue.
   */
  precedingJobs?: number | null;
  /**
   * An estimated date / time for when the job will start.
   */
  startAt?: string | null;
  /**
   * An estimated date / time for when the job will complete.
   */
  completeAt?: string | null;
};

/**
 * Details of a workflow step template.
 */
export type WorkflowStepTemplate = {
  $type: string;
  /**
   * The name of the workflow step. Used to allow steps to refer to one another.
   */
  name?: string | null;
  priority?: Priority;
  /**
   * The maximum time to wait for this step to complete.
   */
  timeout?: string | null;
  /**
   * The maximum number of times this step should be retried.
   */
  retries?: number | null;
  /**
   * A collection of user defined metadata for the workflow step.
   */
  metadata?: {
    [key: string]: unknown;
  } | null;
};

/**
 * Details of a requested workflow.
 */
export type WorkflowTemplate = {
  /**
   * A collection of user defined metadata that can be used to store additional information about the workflow.
   */
  metadata?: {
    [key: string]: unknown;
  } | null;
  /**
   * A list of tags associated with this workflow.
   * Tags are indexed and can be used to search for workflows.
   * At most 10 tags can be assigned to a workflow. Each tag can be at most 200 characters long.
   */
  tags?: Array<string> | null;
  /**
   * An array of steps that compose this workflow.
   */
  steps: Array<WorkflowStepTemplate>;
  /**
   * An array of callbacks to be triggered during the lifetime of the workflow.
   */
  callbacks?: Array<WorkflowCallback> | null;
  tips?: WorkflowTips;
  /**
   * Get an associated collection of arguments
   */
  arguments?: {
    [key: string]: unknown;
  } | null;
  nsfwLevel?: NsfwLevel;
  /**
   * Get or set whether this workflow is experimental
   */
  experimental?: boolean | null;
  /**
   * Get or set whether this workflow should allow mature content.
   * When set to false, the workflow will not return any content that is marked as mature.
   * Additional payment options are available for workflows that do not allow mature content.
   */
  allowMatureContent?: boolean | null;
  upgradeMode?: WorkflowUpgradeMode;
};

export type WorkflowTips = {
  /**
   * The rate of tipping that should be allocated to civitai
   */
  civitai: number;
  /**
   * The rate of tipping that should be allocated to creators involved in this workflow
   */
  creators: number;
};

/**
 * Specifies how a workflow should be upgraded when mature content is detected and green or blue buzz was used for payment.
 */
export const WorkflowUpgradeMode = {
  MANUAL: 'manual',
  AUTOMATIC: 'automatic',
} as const;

/**
 * Specifies how a workflow should be upgraded when mature content is detected and green or blue buzz was used for payment.
 */
export type WorkflowUpgradeMode = (typeof WorkflowUpgradeMode)[keyof typeof WorkflowUpgradeMode];

export type GetBlobData = {
  body?: never;
  path: {
    /**
     * The blob ID to retrieve.
     */
    blobId: string;
  };
  query?: {
    /**
     * The id of the workflow to obtain
     */
    workflowId?: string;
    /**
     * A maximum nsfw level. If this is specified and the blob does not have a NSFW level specified or the NSFW level exceeds our max then we'll return an error
     */
    nsfwLevel?: NsfwLevel;
  };
  url: '/v2/consumer/blobs/{blobId}';
};

export type GetBlobErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type GetBlobError = GetBlobErrors[keyof GetBlobErrors];

export type HeadBlobData = {
  body?: never;
  path: {
    /**
     * Identifies the specific blob to check for existence and NSFW level.
     */
    blobId: string;
  };
  query?: never;
  url: '/v2/consumer/blobs/{blobId}';
};

export type HeadBlobErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type HeadBlobError = HeadBlobErrors[keyof HeadBlobErrors];

export type HeadBlobResponses = {
  /**
   * No Content
   */
  204: void;
};

export type HeadBlobResponse = HeadBlobResponses[keyof HeadBlobResponses];

export type InvokeAgeClassificationStepTemplateData = {
  body?: AgeClassificationInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/ageClassification';
};

export type InvokeAgeClassificationStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeAgeClassificationStepTemplateError =
  InvokeAgeClassificationStepTemplateErrors[keyof InvokeAgeClassificationStepTemplateErrors];

export type InvokeAgeClassificationStepTemplateResponses = {
  /**
   * OK
   */
  200: AgeClassificationOutput;
};

export type InvokeAgeClassificationStepTemplateResponse =
  InvokeAgeClassificationStepTemplateResponses[keyof InvokeAgeClassificationStepTemplateResponses];

export type InvokeComfyStepTemplateData = {
  body?: ComfyInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/comfy';
};

export type InvokeComfyStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeComfyStepTemplateError =
  InvokeComfyStepTemplateErrors[keyof InvokeComfyStepTemplateErrors];

export type InvokeComfyStepTemplateResponses = {
  /**
   * OK
   */
  200: ComfyOutput;
};

export type InvokeComfyStepTemplateResponse =
  InvokeComfyStepTemplateResponses[keyof InvokeComfyStepTemplateResponses];

export type InvokeEchoStepTemplateData = {
  body?: EchoInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/echo';
};

export type InvokeEchoStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeEchoStepTemplateError =
  InvokeEchoStepTemplateErrors[keyof InvokeEchoStepTemplateErrors];

export type InvokeEchoStepTemplateResponses = {
  /**
   * OK
   */
  200: EchoOutput;
};

export type InvokeEchoStepTemplateResponse =
  InvokeEchoStepTemplateResponses[keyof InvokeEchoStepTemplateResponses];

export type InvokeImageGenStepTemplateData = {
  body?: ImageGenInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/imageGen';
};

export type InvokeImageGenStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeImageGenStepTemplateError =
  InvokeImageGenStepTemplateErrors[keyof InvokeImageGenStepTemplateErrors];

export type InvokeImageGenStepTemplateResponses = {
  /**
   * OK
   */
  200: ImageGenOutput;
};

export type InvokeImageGenStepTemplateResponse =
  InvokeImageGenStepTemplateResponses[keyof InvokeImageGenStepTemplateResponses];

export type InvokeImageResourceTrainingStepTemplateData = {
  body?: ImageResourceTrainingInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/imageResourceTraining';
};

export type InvokeImageResourceTrainingStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeImageResourceTrainingStepTemplateError =
  InvokeImageResourceTrainingStepTemplateErrors[keyof InvokeImageResourceTrainingStepTemplateErrors];

export type InvokeImageResourceTrainingStepTemplateResponses = {
  /**
   * OK
   */
  200: ImageResourceTrainingOutput;
};

export type InvokeImageResourceTrainingStepTemplateResponse =
  InvokeImageResourceTrainingStepTemplateResponses[keyof InvokeImageResourceTrainingStepTemplateResponses];

export type InvokeImageUploadStepTemplateData = {
  body?: string;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/imageUpload';
};

export type InvokeImageUploadStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeImageUploadStepTemplateError =
  InvokeImageUploadStepTemplateErrors[keyof InvokeImageUploadStepTemplateErrors];

export type InvokeImageUploadStepTemplateResponses = {
  /**
   * OK
   */
  200: ImageUploadOutput;
};

export type InvokeImageUploadStepTemplateResponse =
  InvokeImageUploadStepTemplateResponses[keyof InvokeImageUploadStepTemplateResponses];

export type InvokeTextToImageStepTemplateData = {
  body?: TextToImageInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/textToImage';
};

export type InvokeTextToImageStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeTextToImageStepTemplateError =
  InvokeTextToImageStepTemplateErrors[keyof InvokeTextToImageStepTemplateErrors];

export type InvokeTextToImageStepTemplateResponses = {
  /**
   * OK
   */
  200: TextToImageOutput;
};

export type InvokeTextToImageStepTemplateResponse =
  InvokeTextToImageStepTemplateResponses[keyof InvokeTextToImageStepTemplateResponses];

export type InvokeVideoEnhancementStepTemplateData = {
  body?: VideoEnhancementInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/videoEnhancement';
};

export type InvokeVideoEnhancementStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeVideoEnhancementStepTemplateError =
  InvokeVideoEnhancementStepTemplateErrors[keyof InvokeVideoEnhancementStepTemplateErrors];

export type InvokeVideoEnhancementStepTemplateResponses = {
  /**
   * OK
   */
  200: VideoEnhancementOutput;
};

export type InvokeVideoEnhancementStepTemplateResponse =
  InvokeVideoEnhancementStepTemplateResponses[keyof InvokeVideoEnhancementStepTemplateResponses];

export type InvokeVideoGenStepTemplateData = {
  body?: VideoGenInput;
  path?: never;
  query?: never;
  url: '/v2/consumer/recipes/videoGen';
};

export type InvokeVideoGenStepTemplateErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type InvokeVideoGenStepTemplateError =
  InvokeVideoGenStepTemplateErrors[keyof InvokeVideoGenStepTemplateErrors];

export type InvokeVideoGenStepTemplateResponses = {
  /**
   * OK
   */
  200: VideoGenOutput;
};

export type InvokeVideoGenStepTemplateResponse =
  InvokeVideoGenStepTemplateResponses[keyof InvokeVideoGenStepTemplateResponses];

export type InvalidateResourceData = {
  body?: never;
  path: {
    /**
     * A unique ID for the resource being requested. See https://developer.civitai.com/docs/getting-started/ai-resource-identifier for more info on AIRs.
     */
    air: string;
  };
  query?: {
    /**
     * One or more userIds to invalidate early access for
     */
    userId?: Array<number>;
    etag?: string;
  };
  url: '/v2/resources/{air}';
};

export type InvalidateResourceErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
};

export type InvalidateResourceError = InvalidateResourceErrors[keyof InvalidateResourceErrors];

export type InvalidateResourceResponses = {
  /**
   * No Content
   */
  204: void;
};

export type InvalidateResourceResponse =
  InvalidateResourceResponses[keyof InvalidateResourceResponses];

export type GetResourceData = {
  body?: never;
  path: {
    /**
     * A unique ID for the resource being requested. See https://developer.civitai.com/docs/getting-started/ai-resource-identifier for more info on AIRs.
     */
    air: string;
  };
  query?: never;
  url: '/v2/resources/{air}';
};

export type GetResourceErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type GetResourceError = GetResourceErrors[keyof GetResourceErrors];

export type GetResourceResponses = {
  /**
   * OK
   */
  200: ResourceInfo;
};

export type GetResourceResponse = GetResourceResponses[keyof GetResourceResponses];

export type QueryWorkflowsData = {
  body?: never;
  headers?: {
    /**
     * Specify 'application/zip' to get the response as a zip file
     */
    Accept?: string;
  };
  path?: never;
  query?: {
    /**
     * An optional cursor to continue querying workflows from a previous query.
     */
    cursor?: string;
    /**
     * How many workflows to return
     */
    take?: number;
    /**
     * An optional list of tags to query by
     */
    tags?: Array<string>;
    /**
     * An optional additional query that is used to match workflows through metadata
     */
    query?: string;
    /**
     * Whether to return data from oldest to newest
     */
    ascending?: boolean;
    /**
     * When set to true, any blob that has mature won't be available and won't have a URL
     */
    hideMatureContent?: boolean;
  };
  url: '/v2/consumer/workflows';
};

export type QueryWorkflowsErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
};

export type QueryWorkflowsError = QueryWorkflowsErrors[keyof QueryWorkflowsErrors];

export type QueryWorkflowsResponses = {
  /**
   * OK
   */
  200: CursedArrayOfTelemetryCursorAndWorkflow;
};

export type QueryWorkflowsResponse = QueryWorkflowsResponses[keyof QueryWorkflowsResponses];

export type SubmitWorkflowData = {
  body?: WorkflowTemplate;
  path?: never;
  query?: {
    /**
     * Whether to wait for the workflow to complete before returning or to return immediately
     * The request may return a 202 if the clients waits for the workflow to complete and the workflow does not complete within the requested timeout.
     * In which case the client should use the token to query the status of the workflow.
     */
    wait?: number;
    /**
     * Whether to actually submit the workflow or return an estimate on what would happen upon submission
     */
    whatif?: boolean;
    /**
     * When set to true, any blob that has mature won't be available and won't have a URL
     */
    hideMatureContent?: boolean;
  };
  url: '/v2/consumer/workflows';
};

export type SubmitWorkflowErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Forbidden
   */
  403: string;
  /**
   * Too Many Requests
   */
  429: ProblemDetails;
};

export type SubmitWorkflowError = SubmitWorkflowErrors[keyof SubmitWorkflowErrors];

export type SubmitWorkflowResponses = {
  /**
   * OK
   */
  200: Workflow;
  /**
   * Accepted
   */
  202: Workflow;
};

export type SubmitWorkflowResponse = SubmitWorkflowResponses[keyof SubmitWorkflowResponses];

export type DeleteWorkflowData = {
  body?: never;
  path: {
    /**
     * The ID of the workflow to delete.
     */
    workflowId: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}';
};

export type DeleteWorkflowErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type DeleteWorkflowError = DeleteWorkflowErrors[keyof DeleteWorkflowErrors];

export type DeleteWorkflowResponses = {
  /**
   * No Content
   */
  204: void;
};

export type DeleteWorkflowResponse = DeleteWorkflowResponses[keyof DeleteWorkflowResponses];

export type GetWorkflowData = {
  body?: never;
  path: {
    /**
     * The ID of the workflow to get status for
     */
    workflowId: string;
  };
  query?: {
    /**
     * Whether to wait for the workflow to complete before returning or to return immediately
     * The request may return a 202 if the clients waits for the workflow to complete and the workflow does not complete within the requested timeout.
     * In which case the client should use the token to query the status of the workflow.
     */
    wait?: boolean;
    /**
     * When set to true, any blob that has mature won't be available and won't have a URL
     */
    hideMatureContent?: boolean;
  };
  url: '/v2/consumer/workflows/{workflowId}';
};

export type GetWorkflowErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type GetWorkflowError = GetWorkflowErrors[keyof GetWorkflowErrors];

export type GetWorkflowResponses = {
  /**
   * OK
   */
  200: Workflow;
};

export type GetWorkflowResponse = GetWorkflowResponses[keyof GetWorkflowResponses];

export type PatchWorkflowData = {
  /**
   * A valid PATCH document
   */
  body?: JsonPatchDocument;
  path: {
    /**
     * The ID of the workflow to patch
     */
    workflowId: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}';
};

export type PatchWorkflowErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type PatchWorkflowError = PatchWorkflowErrors[keyof PatchWorkflowErrors];

export type PatchWorkflowResponses = {
  /**
   * No Content
   */
  204: void;
};

export type PatchWorkflowResponse = PatchWorkflowResponses[keyof PatchWorkflowResponses];

export type UpdateWorkflowData = {
  /**
   * The details to update on the workflow.
   */
  body?: UpdateWorkflowRequest;
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}';
};

export type UpdateWorkflowErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type UpdateWorkflowError = UpdateWorkflowErrors[keyof UpdateWorkflowErrors];

export type UpdateWorkflowResponses = {
  /**
   * No Content
   */
  204: void;
};

export type UpdateWorkflowResponse = UpdateWorkflowResponses[keyof UpdateWorkflowResponses];

export type RemoveAllWorkflowTagsData = {
  body?: never;
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}/tags';
};

export type RemoveAllWorkflowTagsErrors = {
  /**
   * Bad Request
   */
  400: ValidationProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type RemoveAllWorkflowTagsError =
  RemoveAllWorkflowTagsErrors[keyof RemoveAllWorkflowTagsErrors];

export type RemoveAllWorkflowTagsResponses = {
  /**
   * No Content
   */
  204: void;
};

export type RemoveAllWorkflowTagsResponse =
  RemoveAllWorkflowTagsResponses[keyof RemoveAllWorkflowTagsResponses];

export type AddWorkflowTagData = {
  /**
   * The the tag to add to the workflow.
   */
  body?: string;
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}/tags';
};

export type AddWorkflowTagErrors = {
  /**
   * Bad Request
   */
  400: ValidationProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type AddWorkflowTagError = AddWorkflowTagErrors[keyof AddWorkflowTagErrors];

export type AddWorkflowTagResponses = {
  /**
   * No Content
   */
  204: void;
};

export type AddWorkflowTagResponse = AddWorkflowTagResponses[keyof AddWorkflowTagResponses];

export type RemoveWorkflowTagData = {
  body?: never;
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
    /**
     * The the tag to remove from the workflow.
     */
    tag: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}/tags/{tag}';
};

export type RemoveWorkflowTagErrors = {
  /**
   * Bad Request
   */
  400: ValidationProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type RemoveWorkflowTagError = RemoveWorkflowTagErrors[keyof RemoveWorkflowTagErrors];

export type RemoveWorkflowTagResponses = {
  /**
   * No Content
   */
  204: void;
};

export type RemoveWorkflowTagResponse =
  RemoveWorkflowTagResponses[keyof RemoveWorkflowTagResponses];

export type GetWorkflowStepData = {
  body?: never;
  path: {
    /**
     * The id of the workflow to get status for
     */
    workflowId: string;
    /**
     * The name of the step within the workflow to get status for
     */
    stepName: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}/steps/{stepName}';
};

export type GetWorkflowStepErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type GetWorkflowStepError = GetWorkflowStepErrors[keyof GetWorkflowStepErrors];

export type GetWorkflowStepResponses = {
  /**
   * OK
   */
  200: WorkflowStep;
};

export type GetWorkflowStepResponse = GetWorkflowStepResponses[keyof GetWorkflowStepResponses];

export type PatchWorkflowStepData = {
  body?: JsonPatchDocument;
  path: {
    workflowId: string;
    stepName: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}/steps/{stepName}';
};

export type PatchWorkflowStepErrors = {
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type PatchWorkflowStepError = PatchWorkflowStepErrors[keyof PatchWorkflowStepErrors];

export type PatchWorkflowStepResponses = {
  /**
   * No Content
   */
  204: void;
};

export type PatchWorkflowStepResponse =
  PatchWorkflowStepResponses[keyof PatchWorkflowStepResponses];

export type UpdateWorkflowStepData = {
  /**
   * The details to update on the workflow step.
   */
  body?: UpdateWorkflowStepRequest;
  path: {
    /**
     * The id of the workflow to update.
     */
    workflowId: string;
    /**
     * The name of the step to update.
     */
    stepName: string;
  };
  query?: never;
  url: '/v2/consumer/workflows/{workflowId}/steps/{stepName}';
};

export type UpdateWorkflowStepErrors = {
  /**
   * Bad Request
   */
  400: ProblemDetails;
  /**
   * Unauthorized
   */
  401: ProblemDetails;
  /**
   * Not Found
   */
  404: ProblemDetails;
};

export type UpdateWorkflowStepError = UpdateWorkflowStepErrors[keyof UpdateWorkflowStepErrors];

export type UpdateWorkflowStepResponses = {
  /**
   * No Content
   */
  204: void;
};

export type UpdateWorkflowStepResponse =
  UpdateWorkflowStepResponses[keyof UpdateWorkflowStepResponses];

export type ClientOptions = {
  baseUrl: `${string}://swagger.json` | (string & {});
};
