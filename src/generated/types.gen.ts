// This file is auto-generated by @hey-api/openapi-ts

export type AgeClassificationInput = {
  /**
   * An optional model to use for age classification. If not provided, the default model will determined by the worker
   */
  model?: string | null;
  /**
   * The URL of the media to classify. This can either be a URL to an image or a video or a ZIP containing multiple images
   */
  mediaUrl: string;
};

export type AgeClassificationOutput = {
  labels: {
    [key: string]: Array<AgeClassifierLabel>;
  };
  hasMinor: boolean;
  prediction: AgeClassificationPrediction;
};

export type AgeClassificationPrediction = 'pass' | 'fail';

export const AgeClassificationPrediction = {
  PASS: 'pass',
  FAIL: 'fail',
} as const;

/**
 * Age classification
 */
export type AgeClassificationStep = WorkflowStep & {
  input: AgeClassificationInput;
  output?: AgeClassificationOutput;
} & {
  $type: 'ageClassification';
};

export type $type = 'ageClassification';

export const $type = {
  AGE_CLASSIFICATION: 'ageClassification',
} as const;

/**
 * Age classification
 */
export type AgeClassificationStepTemplate = WorkflowStepTemplate & {
  input: AgeClassificationInput;
} & {
  $type: 'ageClassification';
};

export type AgeClassifierLabel = {
  age: string;
  isMinor: boolean;
  boundingBox: Array<number>;
};

export type BatchOCRSafetyClassificationInput = {
  mediaUrls: Array<string>;
};

export type BatchOCRSafetyClassificationOutput = {
  results: Array<BatchOCRSafetyClassificationResult>;
};

export type BatchOCRSafetyClassificationResult = {
  mediaUrl: string;
  classification: string;
  text?: string | null;
};

/**
 * Represents a blob that gets produced as part of a specific job
 */
export type Blob = {
  type: string;
  /**
   * Gets the id of the blob that contains this image.
   */
  id: string;
  /**
   * Gets a value indicating whether the blob is available.
   */
  available: boolean;
  /**
   * Gets a url that can be used to preview the blob.
   */
  url?: string | null;
  /**
   * Get when the url is set to expire
   */
  urlExpiresAt?: string | null;
  /**
   * Get the id of the job that is associated with this blob.
   */
  jobId?: string | null;
  nsfwLevel?: NSFWLevel;
  /**
   * Get an optional reason for why the blob was blocked. This is only set if the blob was blocked.
   */
  blockedReason?: string | null;
};

export type BuzzClientAccount = 'user' | 'generation';

export const BuzzClientAccount = {
  USER: 'user',
  GENERATION: 'generation',
} as const;

export type ComfyInput = {
  /**
   * Get the comfy workflow that needs to be executed
   */
  comfyWorkflow: {
    [key: string]: ComfyNode;
  };
  /**
   * The number of jobs to start with this workflow.
   */
  quantity?: number;
  /**
   * External metadata that will be stored with the image
   */
  imageMetadata?: string | null;
  /**
   * Opt-into using the spine controller exclusively
   */
  useSpineComfy?: boolean | null;
};

export type ComfyNode = {
  classType: string;
  meta?: {
    [key: string]: string;
  } | null;
  isChanged?: string | null;
  inputs: {
    [key: string]: string | number | boolean | [number, number];
  };
};

export type ComfyOutput = {
  /**
   * Get a list of blobs that got generated by this comfy workflow step.
   */
  blobs?: Array<Blob>;
};

/**
 * Comfy workflows
 */
export type ComfyStep = WorkflowStep & {
  input: ComfyInput;
  output?: ComfyOutput;
} & {
  $type: 'comfy';
};

export type $type2 = 'comfy';

export const $type2 = {
  COMFY: 'comfy',
} as const;

/**
 * Comfy workflows
 */
export type ComfyStepTemplate = WorkflowStepTemplate & {
  input: ComfyInput;
} & {
  $type: 'comfy';
};

export type ContainerFormat = 'mp4' | 'webM';

export const ContainerFormat = {
  MP4: 'mp4',
  WEB_M: 'webM',
} as const;

export type CursedArrayOfTelemetryCursorAndWorkflow = {
  next: string;
  items: Array<Workflow>;
};

/**
 * Represents the input information needed for the Echo workflow step.
 */
export type EchoInput = {
  /**
   * The message to be returned in the output.
   */
  message: string;
};

/**
 * Represents the output information returned from the Echo workflow step.
 */
export type EchoOutput = {
  /**
   * The message to be returned.
   */
  message: string;
};

/**
 * Echo
 */
export type EchoStep = WorkflowStep & {
  input: EchoInput;
  output?: EchoOutput;
} & {
  $type: 'echo';
};

export type $type3 = 'echo';

export const $type3 = {
  ECHO: 'echo',
} as const;

/**
 * Echo
 */
export type EchoStepTemplate = WorkflowStepTemplate & {
  input: EchoInput;
} & {
  $type: 'echo';
};

/**
 * An epock result.
 */
export type EpochResult = {
  epochNumber?: number;
  /**
   * Get the name of the generated epoch assets
   */
  blobName: string;
  /**
   * Get the total size in bytes of the asset
   */
  blobSize?: number | null;
  /**
   * Get a list of the names of the blobs that represent sample images
   */
  sampleImages?: Array<string>;
  /**
   * A presigned url that points to the epoch file
   */
  blobUrl: string;
};

export type FileFormat =
  | 'unknown'
  | 'safeTensor'
  | 'pickleTensor'
  | 'diffusers'
  | 'coreML'
  | 'onnx';

export const FileFormat = {
  UNKNOWN: 'unknown',
  SAFE_TENSOR: 'safeTensor',
  PICKLE_TENSOR: 'pickleTensor',
  DIFFUSERS: 'diffusers',
  CORE_ML: 'coreML',
  ONNX: 'onnx',
} as const;

export type Flux1KontextDevImageGenInput = Flux1KontextImageGenInput & {
  [key: string]: unknown;
} & {
  model: 'dev';
};

export type model = 'dev';

export const model = {
  DEV: 'dev',
} as const;

export type Flux1KontextImageGenInput = ImageGenInput & {
  model: string;
  prompt: string;
  images?: Array<string>;
  aspectRatio?: '21:9' | '16:9' | '4:3' | '3:2' | '1:1' | '2:3' | '3:4' | '9:16' | '9:21';
  outputFormat?: 'jpeg' | 'png';
  guidanceScale?: number;
  quantity?: number;
  seed?: number | null;
} & {
  engine: 'flux1-kontext';
};

export type aspectRatio = '21:9' | '16:9' | '4:3' | '3:2' | '1:1' | '2:3' | '3:4' | '9:16' | '9:21';

export const aspectRatio = {
  _21_9: '21:9',
  _16_9: '16:9',
  _4_3: '4:3',
  _3_2: '3:2',
  _1_1: '1:1',
  _2_3: '2:3',
  _3_4: '3:4',
  _9_16: '9:16',
  _9_21: '9:21',
} as const;

export type outputFormat = 'jpeg' | 'png';

export const outputFormat = {
  JPEG: 'jpeg',
  PNG: 'png',
} as const;

export type engine = 'flux1-kontext';

export const engine = {
  FLUX1_KONTEXT: 'flux1-kontext',
} as const;

export type Flux1KontextMaxImageGenInput = Flux1KontextImageGenInput & {
  [key: string]: unknown;
} & {
  model: 'max';
};

export type model2 = 'max';

export const model2 = {
  MAX: 'max',
} as const;

export type Flux1KontextProImageGenInput = Flux1KontextImageGenInput & {
  [key: string]: unknown;
} & {
  model: 'pro';
};

export type model3 = 'pro';

export const model3 = {
  PRO: 'pro',
} as const;

export type FluxDevFastImageResourceTrainingInput = ImageResourceTrainingInput & {
  [key: string]: unknown;
} & {
  engine: 'flux-dev-fast';
};

export type engine2 = 'flux-dev-fast';

export const engine2 = {
  FLUX_DEV_FAST: 'flux-dev-fast',
} as const;

export type GoogleImageGenInput = ImageGenInput & {
  model: string;
  prompt: string;
} & {
  engine: 'google';
};

export type engine3 = 'google';

export const engine3 = {
  GOOGLE: 'google',
} as const;

export type HaiperVideoGenAspectRatio = '16:9' | '4:3' | '1:1' | '9:16' | '3:4';

export const HaiperVideoGenAspectRatio = {
  _16_9: '16:9',
  _4_3: '4:3',
  _1_1: '1:1',
  _9_16: '9:16',
  _3_4: '3:4',
} as const;

export type HaiperVideoGenCameraMovement =
  | 'none'
  | 'panRight'
  | 'panLeft'
  | 'tiltUp'
  | 'tiltDown'
  | 'zoomIn'
  | 'zoomOut';

export const HaiperVideoGenCameraMovement = {
  NONE: 'none',
  PAN_RIGHT: 'panRight',
  PAN_LEFT: 'panLeft',
  TILT_UP: 'tiltUp',
  TILT_DOWN: 'tiltDown',
  ZOOM_IN: 'zoomIn',
  ZOOM_OUT: 'zoomOut',
} as const;

export type HaiperVideoGenInput = VideoGenInput & {
  negativePrompt?: string | null;
  cameraMovement?: HaiperVideoGenCameraMovement;
  seed?: number;
  duration?: 2 | 4 | 8;
  aspectRatio?: HaiperVideoGenAspectRatio;
  model?: HaiperVideoGenModel;
  resolution?: 720 | 1080 | 2160;
  enablePromptEnhancer?: boolean;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
} & {
  engine: 'haiper';
};

export type duration = 2 | 4 | 8;

export const duration = {
  _2: 2,
  _4: 4,
  _8: 8,
} as const;

export type resolution = 720 | 1080 | 2160;

export const resolution = {
  _720: 720,
  _1080: 1080,
  _2160: 2160,
} as const;

export type engine4 = 'haiper';

export const engine4 = {
  HAIPER: 'haiper',
} as const;

export type HaiperVideoGenModel = 'v1_5' | 'v2';

export const HaiperVideoGenModel = {
  V1_5: 'v1_5',
  V2: 'v2',
} as const;

export type HaiperVideoGenOutput = VideoGenOutput & {
  progress?: number | null;
  externalTOSViolation?: boolean | null;
  message?: string | null;
};

export type HumanoidImageMaskCategory = 'dresses' | 'upperBody' | 'lowerBody';

export const HumanoidImageMaskCategory = {
  DRESSES: 'dresses',
  UPPER_BODY: 'upperBody',
  LOWER_BODY: 'lowerBody',
} as const;

export type HumanoidImageMaskInput = {
  imageUrl: string;
  category: HumanoidImageMaskCategory;
};

export type HumanoidImageMaskOutput = {
  blob: Blob;
};

export type HunyuanVdeoGenInput = VideoGenInput & {
  cfgScale?: number;
  frameRate?: number;
  duration?: number;
  seed?: number | null;
  steps?: number;
  width?: number;
  height?: number;
  loras?: Array<VideoGenInputLora>;
  model?: string | null;
} & {
  engine: 'hunyuan';
};

export type engine5 = 'hunyuan';

export const engine5 = {
  HUNYUAN: 'hunyuan',
} as const;

export type ImageBlob = Blob & {
  width?: number | null;
  height?: number | null;
} & {
  type: 'image';
};

export type type = 'image';

export const type = {
  IMAGE: 'image',
} as const;

export type ImageGenInput = {
  engine: string;
};

export type ImageGenOutput = {
  /**
   * A collection of output images.
   */
  images: Array<ImageBlob>;
};

/**
 * Image Generation
 */
export type ImageGenStep = WorkflowStep & {
  input: ImageGenInput;
  output?: ImageGenOutput;
} & {
  $type: 'imageGen';
};

export type $type4 = 'imageGen';

export const $type4 = {
  IMAGE_GEN: 'imageGen',
} as const;

/**
 * Image Generation
 */
export type ImageGenStepTemplate = WorkflowStepTemplate & {
  input: ImageGenInput;
} & {
  $type: 'imageGen';
};

/**
 * Information for a controlnet provided for a text to image input.
 */
export type ImageJobControlNet = {
  preprocessor?: ImageTransformer;
  /**
   * A value representing the weight applied to the ControlNet.
   */
  weight?: number;
  /**
   * A value representing the start step selected for the ControlNet.
   */
  startStep?: number;
  /**
   * A value representing the end step selected for the ControlNet.
   */
  endStep?: number;
};

export type ImageJobNetworkParams = {
  /**
   * In case of Lora and LoCon, set the strength of the network
   */
  strength?: number | null;
  /**
   * In case of a TextualInversion, set the trigger word of the network
   */
  triggerWord?: string | null;
  /**
   * A legacy type set by the consumer
   */
  type?: string | null;
};

export type ImageResouceTrainingModerationStatus =
  | 'evaluating'
  | 'underReview'
  | 'approved'
  | 'rejected';

export const ImageResouceTrainingModerationStatus = {
  EVALUATING: 'evaluating',
  UNDER_REVIEW: 'underReview',
  APPROVED: 'approved',
  REJECTED: 'rejected',
} as const;

/**
 * Input for an image resource training step.
 */
export type ImageResourceTrainingInput = {
  engine: string;
  /**
   * The primary model to train upon.
   */
  model: string;
  /**
   * A url referring data to use in training.
   */
  trainingData: string;
  /**
   * The number of images embedded in this training data. This is used to calculate the cost of training.
   */
  trainingDataImagesCount: number;
  /**
   * The desired lora name.
   */
  loraName?: string;
  /**
   * A selection of sample prompts.
   */
  samplePrompts?: Array<string>;
};

export type ImageResourceTrainingOutput = {
  moderationStatus: ImageResouceTrainingModerationStatus;
  /**
   * An array of epochs.
   */
  epochs: Array<EpochResult>;
  /**
   * The selected prompts for sample images
   */
  sampleImagesPrompts: Array<string>;
  /**
   * The selected images for sample images
   */
  sampleInputImages?: Array<string> | null;
  /**
   * Get wether the blobs are actually stored as assets
   * Assets are deprecated and require a different retrieval mechanism
   */
  storedAsAssets?: boolean | null;
  /**
   * Get an estimate in minutes on how long the work is expected to take
   */
  eta?: number | null;
};

/**
 * LORA Training
 */
export type ImageResourceTrainingStep = WorkflowStep & {
  input: ImageResourceTrainingInput;
  output?: ImageResourceTrainingOutput;
} & {
  $type: 'imageResourceTraining';
};

export type $type5 = 'imageResourceTraining';

export const $type5 = {
  IMAGE_RESOURCE_TRAINING: 'imageResourceTraining',
} as const;

/**
 * LORA Training
 */
export type ImageResourceTrainingStepTemplate = WorkflowStepTemplate & {
  input: ImageResourceTrainingInput;
} & {
  $type: 'imageResourceTraining';
};

/**
 * Available image transformers.
 */
export type ImageTransformer = 'canny' | 'depthZoe' | 'softedgePidinet' | 'rembg';

/**
 * Available image transformers.
 */
export const ImageTransformer = {
  CANNY: 'canny',
  DEPTH_ZOE: 'depthZoe',
  SOFTEDGE_PIDINET: 'softedgePidinet',
  REMBG: 'rembg',
} as const;

export type ImageUploadOutput = {
  blob: Blob;
};

/**
 * Image upload
 */
export type ImageUploadStep = WorkflowStep & {
  /**
   * The workflow's input.
   */
  input: string;
  output?: ImageUploadOutput;
} & {
  $type: 'imageUpload';
};

export type $type6 = 'imageUpload';

export const $type6 = {
  IMAGE_UPLOAD: 'imageUpload',
} as const;

/**
 * Image upload
 */
export type ImageUploadStepTemplate = WorkflowStepTemplate & {
  /**
   * Input for the ImageUploadStep step.
   */
  input: string | null;
} & {
  $type: 'imageUpload';
};

export type Imagen4ImageGenInput = GoogleImageGenInput & {
  prompt: string;
  negativePrompt?: string;
  aspectRatio?: '1:1' | '16:9' | '9:16' | '3:4' | '4:3';
  numImages?: number;
  seed?: number | null;
} & {
  model: 'imagen4';
};

export type aspectRatio2 = '1:1' | '16:9' | '9:16' | '3:4' | '4:3';

export const aspectRatio2 = {
  _1_1: '1:1',
  _16_9: '16:9',
  _9_16: '9:16',
  _3_4: '3:4',
  _4_3: '4:3',
} as const;

export type model4 = 'imagen4';

export const model4 = {
  IMAGEN4: 'imagen4',
} as const;

/**
 * Available levels of job support.
 */
export type JobSupport = 'unsupported' | 'unavailable' | 'available';

/**
 * Available levels of job support.
 */
export const JobSupport = {
  UNSUPPORTED: 'unsupported',
  UNAVAILABLE: 'unavailable',
  AVAILABLE: 'available',
} as const;

/**
 * Array of operations to perform
 */
export type JsonPatchDocument = Array<JsonPatchOperation>;

/**
 * Describes a single operation in a JSON Patch document. Includes the operation type, the target property path, and the value to be used.
 */
export type JsonPatchOperation = {
  /**
   * The operation type. Allowed values: 'add', 'remove', 'replace', 'move', 'copy', 'test'.
   */
  op: 'add' | 'remove' | 'replace' | 'move' | 'copy' | 'test';
  /**
   * The JSON Pointer path to the property in the target document where the operation is to be applied.
   */
  path: string;
  /**
   * Should be a path, required when using move, copy
   */
  from?: string;
  /**
   * The value to apply for 'add', 'replace', or 'test' operations. Not required for 'remove', 'move', or 'copy'.
   */
  value?:
    | string
    | number
    | boolean
    | {
        [key: string]: unknown;
      }
    | unknown[]
    | null;
};

/**
 * The operation type. Allowed values: 'add', 'remove', 'replace', 'move', 'copy', 'test'.
 */
export type op = 'add' | 'remove' | 'replace' | 'move' | 'copy' | 'test';

/**
 * The operation type. Allowed values: 'add', 'remove', 'replace', 'move', 'copy', 'test'.
 */
export const op = {
  ADD: 'add',
  REMOVE: 'remove',
  REPLACE: 'replace',
  MOVE: 'move',
  COPY: 'copy',
  TEST: 'test',
} as const;

export type KlingCameraControl = {
  config?: KlingCameraControlConfig;
};

export type KlingCameraControlConfig = {
  /**
   * Horizontal, controls the camera's movement along the horizontal axis (translation along the x-axis).
   */
  horizontal?: number | null;
  /**
   * Vertical, controls the camera's movement along the vertical axis (translation along the y-axis).
   */
  vertical?: number | null;
  /**
   * Pan, controls the camera's rotation in the horizontal plane (rotation around the y-axis).
   */
  pan?: number | null;
  /**
   * Tilt, controls the camera's rotation in the horizontal plane (rotation around the y-axis).
   */
  tilt?: number | null;
  /**
   * Roll, controls the camera's rolling amount (rotation around the z-axis).
   */
  roll?: number | null;
  /**
   * Zoom, controls the change in the camera's focal length, affecting the proximity of the field of view.
   */
  zoom?: number | null;
};

export type KlingMode = 'standard' | 'professional';

export const KlingMode = {
  STANDARD: 'standard',
  PROFESSIONAL: 'professional',
} as const;

export type KlingModel = 'v1' | 'v1_5' | 'v1_6' | 'v2';

export const KlingModel = {
  V1: 'v1',
  V1_5: 'v1_5',
  V1_6: 'v1_6',
  V2: 'v2',
} as const;

export type KlingVideoGenAspectRatio = '16:9' | '9:16' | '1:1';

export const KlingVideoGenAspectRatio = {
  _16_9: '16:9',
  _9_16: '9:16',
  _1_1: '1:1',
} as const;

export type KlingVideoGenDuration = '5' | '10';

export const KlingVideoGenDuration = {
  _5: '5',
  _10: '10',
} as const;

export type KlingVideoGenInput = VideoGenInput & {
  model?: KlingModel;
  negativePrompt?: string | null;
  cfgScale?: number;
  mode?: KlingMode;
  aspectRatio?: KlingVideoGenAspectRatio;
  duration?: KlingVideoGenDuration;
  cameraControl?: KlingCameraControl;
  sourceImageUrl?: string | null;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
} & {
  engine: 'kling';
};

export type engine6 = 'kling';

export const engine6 = {
  KLING: 'kling',
} as const;

export type KohyaImageResourceTrainingInput = ImageResourceTrainingInput & {
  /**
   * An epoch is one set of learning. By default, we will save a maximum of 20 epochs (evenly distributed), and they are all available for download.
   */
  maxTrainEpochs?: number;
  /**
   * Num Repeats defines how many times each individual image gets put into VRAM. As opposed to batch size, which is how many images are placed into VRAM at once.
   */
  numRepeats?: number;
  /**
   * Batch size is the number of images that will be placed into VRAM at once. A batch size of 2 will train two images at a time, simultaneously.
   */
  trainBatchSize?: number | null;
  /**
   * Specify the maximum resolution of training images. If the training images exceed the resolution specified here, they will be scaled down to this resolution
   */
  resolution?: number | null;
  /**
   * Sorts images into buckets by size for the purposes of training. If your training images are all the same size, you can turn this option off, but leaving it on has no effect.
   */
  enableBucket?: boolean;
  /**
   * Randomly changes the order of your tags during training. The intent of shuffling is to improve learning. If you are using captions (sentences), this option has no meaning.
   */
  shuffleCaption?: boolean;
  /**
   * If your training images have tags, you can randomly shuffle them.
   * However, if you have words that you want to keep at the beginning, you can use this option to specify "Keep the first 0 words at the beginning".
   * This option does nothing if the Shuffle Tags option is off.
   */
  keepTokens?: number;
  /**
   * Determines which layer's vector output will be used. There are 12 layers, and setting the skip will select "xth from the end" of the total layers. For anime, we use 2. For everything else, 1.
   */
  clipSkip?: number;
  /**
   * If this option is turned on, the image will be horizontally flipped randomly. It can learn left and right angles, which is useful when you want to learn symmetrical people and objects.
   */
  flipAugmentation?: boolean;
  /**
   * Sets the learning rate for U-Net. This is the learning rate when performing additional learning on each attention block (and other blocks depending on the setting) in U-Net
   */
  unetLR?: number;
  /**
   * Sets the learning rate for the text encoder. The effect of additional training on text encoders affects the entire U-Net.
   */
  textEncoderLR?: number;
  /**
   * You can change the learning rate in the middle of learning. A scheduler is a setting for how to change the learning rate.
   */
  lrScheduler?: 'constant' | 'cosine' | 'cosine_with_restarts' | 'linear' | null;
  /**
   * This option specifies how many cycles the scheduler runs during training. It is only used when "cosine_with_restarts" or "polynomial" is used as the scheduler.
   */
  lrSchedulerNumCycles?: number;
  /**
   * Learning is performed by putting noise of various strengths on the training image,
   * but depending on the difference in strength of the noise on which it is placed, learning will be
   * stable by moving closer to or farther from the learning target.
   *
   * Min SNR gamma was introduced to compensate for that. When learning images have little noise,
   * it may deviate greatly from the target, so try to suppress this jump.
   */
  minSnrGamma?: number | null;
  /**
   * The larger the Dim setting, the more learning information can be stored, but the possibility of learning unnecessary information other than the learning target increases. A larger Dim also increases LoRA file size.
   */
  networkDim?: number | null;
  /**
   * The smaller the Network alpha value, the larger the stored LoRA neural net weights.
   * For example, with an Alpha of 16 and a Dim of 32, the strength of the weight used is 16/32 = 0.5,
   * meaning that the learning rate is only half as powerful as the Learning Rate setting.
   *
   * If Alpha and Dim are the same number, the strength used will be 1 and will have no effect on the learning rate.
   */
  networkAlpha?: number | null;
  /**
   * Adds noise to training images. 0 adds no noise at all. A value of 1 adds strong noise.
   */
  noiseOffset?: number | null;
  /**
   * The optimizer determines how to update the neural net weights during training.
   * Various methods have been proposed for smart learning, but the most commonly used in LoRA learning
   * is "AdamW8bit" or "Adafactor" for SDXL.
   */
  optimizerType?: string | null;
  readonly targetSteps?: number | null;
} & {
  engine: 'kohya';
};

/**
 * You can change the learning rate in the middle of learning. A scheduler is a setting for how to change the learning rate.
 */
export type lrScheduler = 'constant' | 'cosine' | 'cosine_with_restarts' | 'linear';

/**
 * You can change the learning rate in the middle of learning. A scheduler is a setting for how to change the learning rate.
 */
export const lrScheduler = {
  CONSTANT: 'constant',
  COSINE: 'cosine',
  COSINE_WITH_RESTARTS: 'cosine_with_restarts',
  LINEAR: 'linear',
} as const;

export type engine7 = 'kohya';

export const engine7 = {
  KOHYA: 'kohya',
} as const;

export type LightricksAspectRatio = '1:1' | '16:9' | '9:16' | '3:2' | '2:3';

export const LightricksAspectRatio = {
  _1_1: '1:1',
  _16_9: '16:9',
  _9_16: '9:16',
  _3_2: '3:2',
  _2_3: '2:3',
} as const;

export type LightricksVideoGenInput = VideoGenInput & {
  negativePrompt?: string | null;
  cfgScale?: number;
  frameRate?: number;
  duration?: number;
  seed?: number | null;
  steps?: number;
  aspectRatio?: LightricksAspectRatio;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
  expandPrompt?: boolean;
} & {
  engine: 'lightricks';
};

export type engine8 = 'lightricks';

export const engine8 = {
  LIGHTRICKS: 'lightricks',
} as const;

export type MiniMaxVideoGenInput = VideoGenInput & {
  model?: MiniMaxVideoGenModel;
  enablePromptEnhancer?: boolean;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
} & {
  engine: 'minimax';
};

export type engine9 = 'minimax';

export const engine9 = {
  MINIMAX: 'minimax',
} as const;

export type MiniMaxVideoGenModel = 'hailou';

export const MiniMaxVideoGenModel = {
  HAILOU: 'hailou',
} as const;

export type MochiVideoGenInput = VideoGenInput & {
  seed?: number;
  enablePromptEnhancer?: boolean;
} & {
  engine: 'mochi';
};

export type engine10 = 'mochi';

export const engine10 = {
  MOCHI: 'mochi',
} as const;

export type MusubiImageResourceTrainingInput = ImageResourceTrainingInput & {
  /**
   * An epoch is one set of learning. By default, we will save a maximum of 20 epochs (evenly distributed), and they are all available for download.
   */
  maxTrainEpochs?: number;
  /**
   * Num Repeats defines how many times each individual image gets put into VRAM. As opposed to batch size, which is how many images are placed into VRAM at once.
   */
  numRepeats?: number;
  /**
   * Batch size is the number of images that will be placed into VRAM at once. A batch size of 2 will train two images at a time, simultaneously.
   */
  trainBatchSize?: number | null;
  /**
   * Specify the maximum resolution of training images. If the training images exceed the resolution specified here, they will be scaled down to this resolution
   */
  resolution?: number | null;
  /**
   * Sorts images into buckets by size for the purposes of training. If your training images are all the same size, you can turn this option off, but leaving it on has no effect.
   */
  enableBucket?: boolean;
  /**
   * Sets the learning rate for U-Net. This is the learning rate when performing additional learning on each attention block (and other blocks depending on the setting) in U-Net
   */
  unetLR?: number;
  /**
   * You can change the learning rate in the middle of learning. A scheduler is a setting for how to change the learning rate.
   */
  lrScheduler?: 'constant' | 'cosine' | 'cosine_with_restarts' | 'linear' | null;
  /**
   * This option specifies how many cycles the scheduler runs during training. It is only used when "cosine_with_restarts" or "polynomial" is used as the scheduler.
   */
  lrSchedulerNumCycles?: number;
  /**
   * The larger the Dim setting, the more learning information can be stored, but the possibility of learning unnecessary information other than the learning target increases. A larger Dim also increases LoRA file size.
   */
  networkDim?: number | null;
  /**
   * The smaller the Network alpha value, the larger the stored LoRA neural net weights.
   * For example, with an Alpha of 16 and a Dim of 32, the strength of the weight used is 16/32 = 0.5,
   * meaning that the learning rate is only half as powerful as the Learning Rate setting.
   *
   * If Alpha and Dim are the same number, the strength used will be 1 and will have no effect on the learning rate.
   */
  networkAlpha?: number | null;
  /**
   * The optimizer determines how to update the neural net weights during training.
   * Various methods have been proposed for smart learning, but the most commonly used in LoRA learning
   * is "AdamW8bit" or "Adafactor" for SDXL.
   */
  optimizerType?: string | null;
  readonly targetSteps?: number | null;
} & {
  engine: 'musubi';
};

export type engine11 = 'musubi';

export const engine11 = {
  MUSUBI: 'musubi',
} as const;

export type NSFWLevel = 'pg' | 'pG13' | 'r' | 'x' | 'xxx' | 'na';

export const NSFWLevel = {
  PG: 'pg',
  P_G13: 'pG13',
  R: 'r',
  X: 'x',
  XXX: 'xxx',
  NA: 'na',
} as const;

export type OpenAIDallE2CreateImageGenInput = OpenAIDallE2ImageGenInput & {
  background?: 'auto' | 'transparent' | 'opaque';
} & {
  operation: 'createImage';
};

export type background = 'auto' | 'transparent' | 'opaque';

export const background = {
  AUTO: 'auto',
  TRANSPARENT: 'transparent',
  OPAQUE: 'opaque',
} as const;

export type operation = 'createImage';

export const operation = {
  CREATE_IMAGE: 'createImage',
} as const;

export type OpenAIDallE2EditImageInput = OpenAIDallE2ImageGenInput & {
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  image: string;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  mask?: string | null;
} & {
  operation: 'editImage';
};

export type operation2 = 'editImage';

export const operation2 = {
  EDIT_IMAGE: 'editImage',
} as const;

export type OpenAIDallE2ImageGenInput = OpenApiImageGenInput & {
  operation: string;
  prompt: string;
  size: '256x256' | '512x512' | '1024x1024';
  quantity?: number;
} & {
  model: 'dall-e-2';
};

export type size = '256x256' | '512x512' | '1024x1024';

export const size = {
  _256X256: '256x256',
  _512X512: '512x512',
  _1024X1024: '1024x1024',
} as const;

export type model5 = 'dall-e-2';

export const model5 = {
  DALL_E_2: 'dall-e-2',
} as const;

export type OpenAIDallE3CreateImageGenInput = OpenAIDallE3ImageGenInput & {
  background?: 'auto' | 'transparent' | 'opaque';
} & {
  operation: 'createImage';
};

export type OpenAIDallE3ImageGenInput = OpenApiImageGenInput & {
  operation: string;
  prompt: string;
  size: '1024x1024' | '1792x1024' | '1024x1792';
  style?: 'natural' | 'vivid';
  quality?: 'auto' | 'hd' | 'standard';
} & {
  model: 'dall-e-3';
};

export type size2 = '1024x1024' | '1792x1024' | '1024x1792';

export const size2 = {
  _1024X1024: '1024x1024',
  _1792X1024: '1792x1024',
  _1024X1792: '1024x1792',
} as const;

export type style = 'natural' | 'vivid';

export const style = {
  NATURAL: 'natural',
  VIVID: 'vivid',
} as const;

export type quality = 'auto' | 'hd' | 'standard';

export const quality = {
  AUTO: 'auto',
  HD: 'hd',
  STANDARD: 'standard',
} as const;

export type model6 = 'dall-e-3';

export const model6 = {
  DALL_E_3: 'dall-e-3',
} as const;

export type OpenAIGpt1CreateImageInput = OpenAIGpt1ImageGenInput & {
  [key: string]: unknown;
} & {
  operation: 'createImage';
};

export type OpenAIGpt1EditImageInput = OpenAIGpt1ImageGenInput & {
  images: Array<string>;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  mask?: string | null;
} & {
  operation: 'editImage';
};

export type OpenAIGpt1ImageGenInput = OpenApiImageGenInput & {
  operation: string;
  prompt: string;
  size?: '1024x1024' | '1536x1024' | '1024x1536';
  quantity?: number;
  background?: 'auto' | 'transparent' | 'opaque';
  quality?: 'auto' | 'high' | 'medium' | 'low' | null;
} & {
  model: 'gpt-image-1';
};

export type size3 = '1024x1024' | '1536x1024' | '1024x1536';

export const size3 = {
  _1024X1024: '1024x1024',
  _1536X1024: '1536x1024',
  _1024X1536: '1024x1536',
} as const;

export type quality2 = 'auto' | 'high' | 'medium' | 'low';

export const quality2 = {
  AUTO: 'auto',
  HIGH: 'high',
  MEDIUM: 'medium',
  LOW: 'low',
} as const;

export type model7 = 'gpt-image-1';

export const model7 = {
  GPT_IMAGE_1: 'gpt-image-1',
} as const;

export type OpenApiImageGenInput = ImageGenInput & {
  model: string;
  prompt: string;
} & {
  engine: 'openai';
};

export type engine12 = 'openai';

export const engine12 = {
  OPENAI: 'openai',
} as const;

/**
 * Available options for priority.
 */
export type Priority = 'high' | 'normal' | 'low';

/**
 * Available options for priority.
 */
export const Priority = {
  HIGH: 'high',
  NORMAL: 'normal',
  LOW: 'low',
} as const;

export type ProblemDetails = {
  type?: string | null;
  title?: string | null;
  status?: number | null;
  detail?: string | null;
  instance?: string | null;
  '[key: string]': (unknown | string | number) | undefined;
};

/**
 * Details for a specific resource.
 */
export type ResourceInfo = {
  /**
   * An AIR ID for the resource.
   */
  air: string;
  /**
   * The resource size in bytes.
   */
  size: number;
  /**
   * A collection of hashes.
   */
  hashes: {
    [key: string]: string;
  };
  /**
   * An array of download urls.
   */
  downloadUrls: Array<string>;
  /**
   * The name of the resource.
   */
  resourceName?: string | null;
  /**
   * The name of the version.
   */
  versionName?: string | null;
  /**
   * The date time to invalidate at.
   */
  invalidateAt?: string | null;
  /**
   * A DateTime representing when early access for the resource ends.
   */
  earlyAccessEndsAt?: string | null;
  /**
   * A bool indicating if permission is required to use this resource.
   */
  checkPermission?: boolean;
  /**
   * A bool indicating if generation is enabled for this resource.
   */
  canGenerate?: boolean;
  /**
   * An optional limit on the number of uses for this resource per user that has early acccess.
   */
  freeTrialLimit?: number | null;
  /**
   * Wether this resource requires authorization.
   */
  requiresAuthorization?: boolean | null;
  fileFormat?: FileFormat;
  /**
   * A boolean indicating whether this resource restricts mature content generation.
   * If resources with this restriction are used in generation, then generations will automatically be enforced to not generate mature content
   */
  hasMatureContentRestriction?: boolean;
  /**
   * Get a rank between 0-1 on the popularity of the resource.
   */
  popularityRank?: number | null;
  /**
   * Get wether this resource is featured
   */
  isFeatured?: boolean | null;
  /**
   * The date at which this model got published
   */
  publishedAt?: string | null;
  /**
   * A boolean indicating whether this resource restricts to SFW content generation.
   * NSFWContent covers X and AA whereas MatureContent includes R rated content.
   */
  hasNSFWContentRestriction?: boolean;
};

/**
 * The available options for schedulers used in image generation.
 */
export type Scheduler =
  | 'eulerA'
  | 'euler'
  | 'lms'
  | 'heun'
  | 'dpM2'
  | 'dpM2A'
  | 'dpM2SA'
  | 'dpM2M'
  | 'dpmsde'
  | 'dpmFast'
  | 'dpmAdaptive'
  | 'lmsKarras'
  | 'dpM2Karras'
  | 'dpM2AKarras'
  | 'dpM2SAKarras'
  | 'dpM2MKarras'
  | 'dpmsdeKarras'
  | 'ddim'
  | 'plms'
  | 'uniPC'
  | 'undefined'
  | 'lcm'
  | 'ddpm'
  | 'deis'
  | 'dpM3MSDE';

/**
 * The available options for schedulers used in image generation.
 */
export const Scheduler = {
  EULER_A: 'eulerA',
  EULER: 'euler',
  LMS: 'lms',
  HEUN: 'heun',
  DP_M2: 'dpM2',
  DP_M2A: 'dpM2A',
  DP_M2SA: 'dpM2SA',
  DP_M2M: 'dpM2M',
  DPMSDE: 'dpmsde',
  DPM_FAST: 'dpmFast',
  DPM_ADAPTIVE: 'dpmAdaptive',
  LMS_KARRAS: 'lmsKarras',
  DP_M2KARRAS: 'dpM2Karras',
  DP_M2AKARRAS: 'dpM2AKarras',
  DP_M2SAKARRAS: 'dpM2SAKarras',
  DP_M2MKARRAS: 'dpM2MKarras',
  DPMSDE_KARRAS: 'dpmsdeKarras',
  DDIM: 'ddim',
  PLMS: 'plms',
  UNI_PC: 'uniPC',
  UNDEFINED: 'undefined',
  LCM: 'lcm',
  DDPM: 'ddpm',
  DEIS: 'deis',
  DP_M3MSDE: 'dpM3MSDE',
} as const;

/**
 * Input for an text to image step.
 */
export type TextToImageInput = {
  /**
   * The number of batches to run.
   */
  quantity?: number;
  /**
   * The size of each batch
   */
  batchSize?: number;
  /**
   * The AIR of the checkpoint model to use for generation.
   */
  model?: string;
  /**
   * Get or set a associative list of additional networks. Use the AIR of the network as the key.
   */
  additionalNetworks?: {
    [key: string]: ImageJobNetworkParams;
  };
  /**
   * Get or set a associative list of ControlNets.
   */
  controlNets?: Array<ImageJobControlNet>;
  /**
   * The provided text prompt.
   */
  prompt: string;
  /**
   * The provided negative text prompt.
   */
  negativePrompt?: string | null;
  scheduler?: Scheduler;
  /**
   * The number of steps for image generation.
   */
  steps?: number;
  /**
   * The CFG scale value for image generation.
   */
  cfgScale?: number;
  /**
   * The desired image width in pixels.
   */
  width: number;
  /**
   * The desired image height in pixels.
   */
  height: number;
  /**
   * The seed to use in image generation. Defaults to a random value if left unpopulated.
   */
  seed?: number;
  /**
   * The clip skip value for image generation.
   */
  clipSkip?: number;
  /**
   * External metadata that will be stored with the image
   */
  imageMetadata?: string | null;
  /**
   * An optional engine to use for generation.
   */
  engine?: string | null;
};

/**
 * Represents the output of a TextToImage workflow step.
 */
export type TextToImageOutput = {
  /**
   * A collection of output images.
   */
  images: Array<ImageBlob>;
};

/**
 * TextToImage
 */
export type TextToImageStep = WorkflowStep & {
  input: TextToImageInput;
  output?: TextToImageOutput;
} & {
  $type: 'textToImage';
};

export type $type7 = 'textToImage';

export const $type7 = {
  TEXT_TO_IMAGE: 'textToImage',
} as const;

/**
 * TextToImage
 */
export type TextToImageStepTemplate = WorkflowStepTemplate & {
  input: TextToImageInput;
} & {
  $type: 'textToImage';
};

/**
 * Transaction information.
 */
export type TransactionInfo = {
  type: TransactionType;
  /**
   * The transaction amount.
   */
  amount: number;
  /**
   * The transaction ID.
   */
  id?: string | null;
  accountType?: BuzzClientAccount;
};

export type TransactionSummary = {
  /**
   * Get a list of individual transactions.
   */
  list?: Array<TransactionInfo>;
};

export type TransactionType = 'debit' | 'credit';

export const TransactionType = {
  DEBIT: 'debit',
  CREDIT: 'credit',
} as const;

export type TranscodeInput = {
  sourceUrl: string;
  containerFormat?: ContainerFormat;
  width?: number;
  destinationUrl?: string | null;
};

export type TranscodeOutput = {
  /**
   * Gets the id of the blob that contains the media.
   */
  id: string;
  /**
   * Gets a value indicating whether the media is available.
   */
  available: boolean;
  /**
   * Gets a url that can be used to preview the media.
   */
  url?: string | null;
  /**
   * Get when the url is set to expire
   */
  urlExpiresAt?: string | null;
  /**
   * Get the id of the job that is associated with this media.
   */
  jobId: string;
};

/**
 * Transcoding
 */
export type TranscodeStep = WorkflowStep & {
  input: TranscodeInput;
  output?: TranscodeOutput;
} & {
  $type: 'transcode';
};

export type $type8 = 'transcode';

export const $type8 = {
  TRANSCODE: 'transcode',
} as const;

export type TryOnUInput = {
  subjectUrl: string;
  garmentUrl: string;
  subjectMaskUrl?: string;
  subjectMaskBlobKey?: string;
  garmentDescription?: string;
  maskSubject?: boolean;
  cropSubject?: boolean;
  steps?: number;
  seed?: number;
};

export type TryOnUOutput = {
  blob: Blob;
};

/**
 * An request for updating a workflow.
 */
export type UpdateWorkflowRequest = {
  status?: UpdateWorkflowStatus;
  /**
   * An optional set of new properties to set on the workflow.
   */
  metadata?: {
    [key: string]: unknown;
  } | null;
  /**
   * An optional set of new tags to set on the workflow.
   */
  tags?: Array<string> | null;
};

/**
 * Available statuses for updating workflows.
 */
export type UpdateWorkflowStatus = 'canceled';

/**
 * Available statuses for updating workflows.
 */
export const UpdateWorkflowStatus = {
  CANCELED: 'canceled',
} as const;

export type UpdateWorkflowStepRequest = {
  /**
   * An set of new properties to set on the workflow step.
   */
  metadata: {
    [key: string]: unknown;
  };
};

export type ValidationProblemDetails = {
  type?: string | null;
  title?: string | null;
  status?: number | null;
  detail?: string | null;
  instance?: string | null;
  errors?: {
    [key: string]: Array<string>;
  };
  '[key: string]': (unknown | string | number) | undefined;
};

export type ValueTupleOfStringAndInt32 = {
  [key: string]: unknown;
};

export type Veo3AspectRatio = '16:9' | '9:16' | '1:1';

export const Veo3AspectRatio = {
  _16_9: '16:9',
  _9_16: '9:16',
  _1_1: '1:1',
} as const;

export type Veo3VideoGenInput = VideoGenInput & {
  negativePrompt?: string | null;
  enablePromptEnhancer?: boolean;
  aspectRatio?: Veo3AspectRatio;
  duration?: number;
  generateAudio?: boolean;
  seed?: number | null;
} & {
  engine: 'veo3';
};

export type engine13 = 'veo3';

export const engine13 = {
  VEO3: 'veo3',
} as const;

export type VideoBlob = Blob & {
  width?: number | null;
  height?: number | null;
} & {
  type: 'video';
};

export type type2 = 'video';

export const type2 = {
  VIDEO: 'video',
} as const;

export type VideoEnhancementInput = {
  sourceUrl: string;
  upscaler?: VideoEnhancementInputUpscalerOptions;
  interpolation?: VideoEnhancementInputInterpolationOptions;
};

export type VideoEnhancementInputInterpolationOptions = {
  multiplier: number;
};

export type VideoEnhancementInputUpscalerOptions = {
  model?: string | null;
  width: number;
  height: number;
};

export type VideoEnhancementOutput = {
  video: VideoBlob;
};

/**
 * Upscale videos and/or interpolate frames
 */
export type VideoEnhancementStep = WorkflowStep & {
  input: VideoEnhancementInput;
  output?: VideoEnhancementOutput;
} & {
  $type: 'videoEnhancement';
};

export type $type9 = 'videoEnhancement';

export const $type9 = {
  VIDEO_ENHANCEMENT: 'videoEnhancement',
} as const;

/**
 * Upscale videos and/or interpolate frames
 */
export type VideoEnhancementStepTemplate = WorkflowStepTemplate & {
  input: VideoEnhancementInput;
} & {
  $type: 'videoEnhancement';
};

export type VideoGenInput = {
  engine: string;
  prompt: string;
};

export type VideoGenInputLora = {
  air: string;
  strength: number;
};

export type VideoGenOutput = {
  video?: VideoBlob;
};

/**
 * Video generation
 */
export type VideoGenStep = WorkflowStep & {
  input: VideoGenInput;
  output?: VideoGenOutput;
} & {
  $type: 'videoGen';
};

export type $type10 = 'videoGen';

export const $type10 = {
  VIDEO_GEN: 'videoGen',
} as const;

/**
 * Video generation
 */
export type VideoGenStepTemplate = WorkflowStepTemplate & {
  input: VideoGenInput;
} & {
  $type: 'videoGen';
};

export type ViduVideoGenInput = VideoGenInput & {
  enablePromptEnhancer?: boolean;
  seed?: number | null;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
  style?: ViduVideoGenStyle;
  duration?: 4 | 8;
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  endSourceImage?: string | null;
  model?: ViduVideoGenModel;
  aspectRatio?: '16:9' | '9:16' | '1:1' | null;
  movementAmplitude?: 'auto' | 'small' | 'medium' | 'large' | null;
} & {
  engine: 'vidu';
};

export type duration2 = 4 | 8;

export const duration2 = {
  _4: 4,
  _8: 8,
} as const;

export type aspectRatio3 = '16:9' | '9:16' | '1:1';

export const aspectRatio3 = {
  _16_9: '16:9',
  _9_16: '9:16',
  _1_1: '1:1',
} as const;

export type movementAmplitude = 'auto' | 'small' | 'medium' | 'large';

export const movementAmplitude = {
  AUTO: 'auto',
  SMALL: 'small',
  MEDIUM: 'medium',
  LARGE: 'large',
} as const;

export type engine14 = 'vidu';

export const engine14 = {
  VIDU: 'vidu',
} as const;

export type ViduVideoGenModel = 'default' | 'q1';

export const ViduVideoGenModel = {
  DEFAULT: 'default',
  Q1: 'q1',
} as const;

export type ViduVideoGenStyle = 'general' | 'anime';

export const ViduVideoGenStyle = {
  GENERAL: 'general',
  ANIME: 'anime',
} as const;

export type WanVdeoGenInput = VideoGenInput & {
  /**
   * Either A URL, A DataURL or a Base64 string
   */
  sourceImage?: string | null;
  cfgScale?: number;
  frameRate?: number;
  duration?: number;
  seed?: number | null;
  steps?: number;
  width?: number;
  height?: number;
  model?: string | null;
  loras?: Array<VideoGenInputLora>;
  /**
   * Aspect ratio of the output video. Only applicable when using the 720p model.
   */
  aspectRatio?: '4:3' | '16:9' | '9:16';
  /**
   * Whether to enable prompt expansion. Only applicable when using the 720p model.
   */
  enablePromptExpansion?: boolean;
} & {
  engine: 'wan';
};

/**
 * Aspect ratio of the output video. Only applicable when using the 720p model.
 */
export type aspectRatio4 = '4:3' | '16:9' | '9:16';

/**
 * Aspect ratio of the output video. Only applicable when using the 720p model.
 */
export const aspectRatio4 = {
  _4_3: '4:3',
  _16_9: '16:9',
  _9_16: '9:16',
} as const;

export type engine15 = 'wan';

export const engine15 = {
  WAN: 'wan',
} as const;

/**
 * Details of a workflow.
 */
export type Workflow = {
  /**
   * The ID for the workflow.
   */
  id?: string | null;
  /**
   * The date / time the workflow was created.
   */
  createdAt?: string;
  transactions?: TransactionSummary;
  /**
   * A collection of user defined metadata for the workflow.
   */
  metadata?: {
    [key: string]: unknown;
  };
  status?: WorkflowStatus;
  /**
   * The date / time the workflow was started. Null if not yet started.
   */
  startedAt?: string | null;
  /**
   * The date / time the workflow was completed. Null if not yet complete.
   */
  completedAt?: string | null;
  /**
   * An optional list of tags for the workflow.
   */
  tags?: Array<string>;
  /**
   * Get an associated collection of arguments
   */
  arguments?: {
    [key: string]: unknown;
  };
  /**
   * The steps for the workflow.
   */
  steps?: Array<WorkflowStep>;
  /**
   * An array of callback details for the workflow.
   */
  callbacks?: Array<WorkflowCallback>;
  tips?: WorkflowTips;
  cost?: WorkflowCost;
  nsfwLevel?: NSFWLevel;
  /**
   * Get or set whether this workflow is experimental
   */
  experimental?: boolean | null;
};

/**
 * Details of a callback setup for a workflow.
 */
export type WorkflowCallback = {
  /**
   * The url for the callback.
   */
  url: string;
  /**
   * An array of event types to send to the callback.
   */
  type: Array<
    | 'workflow:*'
    | 'workflow:unassigned'
    | 'workflow:processing'
    | 'workflow:succeeded'
    | 'workflow:failed'
    | 'workflow:expired'
    | 'workflow:canceled'
    | 'step:*'
    | 'step:unassigned'
    | 'step:processing'
    | 'step:succeeded'
    | 'step:failed'
    | 'step:expired'
    | 'step:canceled'
    | 'job:*'
    | 'job:unassigned'
    | 'job:processing'
    | 'job:succeeded'
    | 'job:failed'
    | 'job:expired'
    | 'job:canceled'
  >;
};

export type WorkflowCost = {
  /**
   * The base cost of this request, excludsing any tips
   */
  base?: number;
  /**
   * A breakdown of the cost factors for this request
   */
  factors?: {
    [key: string]: number;
  } | null;
  /**
   * A fixed set of cost additions for this request
   */
  fixed?: {
    [key: string]: number;
  } | null;
  tips?: WorkflowCostTips;
  /**
   * The total cost of this request, including tips
   */
  total?: number;
};

/**
 * Get the cost of tips
 */
export type WorkflowCostTips = {
  /**
   * The buzz tipped to Civitai
   */
  civitai: number;
  /**
   * The buzz tipped to the Creators who's resources were used
   */
  creators: number;
};

/**
 * Details of a workflow event.
 */
export type WorkflowEvent = {
  /**
   * The ID that represents the corresponding workflow.
   */
  workflowId: string;
  status: WorkflowStatus;
  /**
   * A timestamp for when this event got raised
   */
  timestamp?: string;
  $type?: string;
};

/**
 * Values available to represent workflow status.
 */
export type WorkflowStatus =
  | 'unassigned'
  | 'preparing'
  | 'scheduled'
  | 'processing'
  | 'succeeded'
  | 'failed'
  | 'expired'
  | 'canceled';

/**
 * Values available to represent workflow status.
 */
export const WorkflowStatus = {
  UNASSIGNED: 'unassigned',
  PREPARING: 'preparing',
  SCHEDULED: 'scheduled',
  PROCESSING: 'processing',
  SUCCEEDED: 'succeeded',
  FAILED: 'failed',
  EXPIRED: 'expired',
  CANCELED: 'canceled',
} as const;

/**
 * Details of a workflow step.
 */
export type WorkflowStep = {
  $type: string;
  /**
   * The name of the workflow step. Used to allow steps to refer to one another.
   */
  name: string;
  priority?: Priority;
  /**
   * The maximum time to wait for this step to complete.
   */
  timeout?: string | null;
  /**
   * The maximum number of times this step should be retried.
   */
  retries?: number | null;
  /**
   * The jobs generated by this step.
   */
  jobs?: Array<WorkflowStepJob> | null;
  status?: WorkflowStatus;
  /**
   * The date / time the step was started. Null if not yet started.
   */
  startedAt?: string | null;
  /**
   * The date / time the step was completed. Null if not yet completed.
   */
  completedAt?: string | null;
  /**
   * A collection of user defined metadata for the workflow step.
   */
  metadata?: {
    [key: string]: unknown;
  };
  /**
   * An estimation on the current progression of this step, or null if there is no estimation
   */
  estimatedProgressRate?: number | null;
};

/**
 * Details of a workflow step event.
 */
export type WorkflowStepEvent = {
  /**
   * The workflow ID.
   */
  workflowId: string;
  /**
   * The workflow step's name.
   */
  stepName: string;
  status: WorkflowStatus;
  $type?: string;
};

/**
 * Details of a job produced by a workflow step.
 */
export type WorkflowStepJob = {
  /**
   * The job's ID.
   */
  id: string;
  status?: WorkflowStatus;
  /**
   * The date / time the job started. Null if not yet started.
   */
  startedAt?: string | null;
  /**
   * The date / time the job completed. Null if not yet completed.
   */
  completedAt?: string | null;
  queuePosition?: WorkflowStepJobQueuePosition;
  /**
   * The job's cost.
   */
  cost?: number;
  /**
   * An estimation on the current progression of this job, or null if there is no estimation
   */
  estimatedProgressRate?: number | null;
};

/**
 * Details of a workflow step job event.
 */
export type WorkflowStepJobEvent = {
  /**
   * The workflow ID.
   */
  workflowId: string;
  /**
   * The step's name.
   */
  stepName: string;
  /**
   * The job's ID.
   */
  jobId: string;
  status: WorkflowStatus;
  $type?: string;
  progress?: number | null;
  reason?: string | null;
  blockedReason?: string | null;
};

/**
 * Details of the workflow step job's queue position.
 */
export type WorkflowStepJobQueuePosition = {
  support: JobSupport;
  /**
   * The number of preceding jobs in the queue.
   */
  precedingJobs?: number | null;
  /**
   * An estimated date / time for when the job will start.
   */
  startAt?: string | null;
  /**
   * An estimated date / time for when the job will complete.
   */
  completeAt?: string | null;
};

/**
 * Details of a workflow step template.
 */
export type WorkflowStepTemplate = {
  $type: string;
  /**
   * The name of the workflow step. Used to allow steps to refer to one another.
   */
  name?: string | null;
  priority?: Priority;
  /**
   * The maximum time to wait for this step to complete.
   */
  timeout?: string | null;
  /**
   * The maximum number of times this step should be retried.
   */
  retries?: number | null;
  /**
   * A collection of user defined metadata for the workflow step.
   */
  metadata?: {
    [key: string]: unknown;
  } | null;
};

/**
 * Details of a requested workflow.
 */
export type WorkflowTemplate = {
  /**
   * A collection of user defined metadata that can be used to store additional information about the workflow.
   */
  metadata?: {
    [key: string]: unknown;
  } | null;
  /**
   * A list of tags associated with this workflow.
   * Tags are indexed and can be used to search for workflows.
   * At most 10 tags can be assigned to a workflow. Each tag can be at most 200 characters long.
   */
  tags?: Array<string> | null;
  /**
   * An array of steps that compose this workflow.
   */
  steps: Array<WorkflowStepTemplate>;
  /**
   * An array of callbacks to be triggered during the lifetime of the workflow.
   */
  callbacks?: Array<WorkflowCallback> | null;
  tips?: WorkflowTips;
  /**
   * Get an associated collection of arguments
   */
  arguments?: {
    [key: string]: unknown;
  } | null;
  nsfwLevel?: NSFWLevel;
  /**
   * Get or set whether this workflow is experimental
   */
  experimental?: boolean | null;
};

export type WorkflowTips = {
  /**
   * The rate of tipping that should be allocated to civitai
   */
  civitai: number;
  /**
   * The rate of tipping that should be allocated to creators involved in this workflow
   */
  creators: number;
};

export type GetBlobData = {
  path: {
    /**
     * The blob ID to retrieve.
     */
    blobId: string;
  };
  query?: {
    /**
     * A maximum nsfw level. If this is specified and the blob does not have a NSFW level specified or the NSFW level exceeds our max then we'll return an error
     */
    nsfwLevel?: NSFWLevel;
  };
};

export type HeadBlobData = {
  path: {
    /**
     * Identifies the specific blob to check for existence and NSFW level.
     */
    blobId: string;
  };
};

export type HeadBlobResponse = void;

export type HeadBlobError = ProblemDetails;

export type InvokeAgeClassificationStepTemplateData = {
  body?: AgeClassificationInput;
};

export type InvokeAgeClassificationStepTemplateResponse = AgeClassificationOutput;

export type InvokeAgeClassificationStepTemplateError = ProblemDetails;

export type InvokeComfyStepTemplateData = {
  body?: ComfyInput;
};

export type InvokeComfyStepTemplateResponse = ComfyOutput;

export type InvokeComfyStepTemplateError = ProblemDetails;

export type InvokeEchoStepTemplateData = {
  body?: EchoInput;
};

export type InvokeEchoStepTemplateResponse = EchoOutput;

export type InvokeEchoStepTemplateError = ProblemDetails;

export type InvokeImageGenStepTemplateData = {
  body?: ImageGenInput;
};

export type InvokeImageGenStepTemplateResponse = ImageGenOutput;

export type InvokeImageGenStepTemplateError = ProblemDetails;

export type InvokeImageResourceTrainingStepTemplateData = {
  body?: ImageResourceTrainingInput;
};

export type InvokeImageResourceTrainingStepTemplateResponse = ImageResourceTrainingOutput;

export type InvokeImageResourceTrainingStepTemplateError = ProblemDetails;

export type InvokeImageUploadStepTemplateData = {
  body?: string;
};

export type InvokeImageUploadStepTemplateResponse = ImageUploadOutput;

export type InvokeImageUploadStepTemplateError = ProblemDetails;

export type InvokeTextToImageStepTemplateData = {
  body?: TextToImageInput;
};

export type InvokeTextToImageStepTemplateResponse = TextToImageOutput;

export type InvokeTextToImageStepTemplateError = ProblemDetails;

export type InvokeVideoEnhancementStepTemplateData = {
  body?: VideoEnhancementInput;
};

export type InvokeVideoEnhancementStepTemplateResponse = VideoEnhancementOutput;

export type InvokeVideoEnhancementStepTemplateError = ProblemDetails;

export type InvokeVideoGenStepTemplateData = {
  body?: VideoGenInput;
};

export type InvokeVideoGenStepTemplateResponse = VideoGenOutput;

export type InvokeVideoGenStepTemplateError = ProblemDetails;

export type GetResourceData = {
  path: {
    /**
     * A unique ID for the resource being requested. See https://developer.civitai.com/docs/getting-started/ai-resource-identifier for more info on AIRs.
     */
    air: string;
  };
};

export type GetResourceResponse = ResourceInfo;

export type GetResourceError = ProblemDetails;

export type InvalidateResourceData = {
  path: {
    /**
     * A unique ID for the resource being requested. See https://developer.civitai.com/docs/getting-started/ai-resource-identifier for more info on AIRs.
     */
    air: string;
  };
  query?: {
    etag?: string;
    /**
     * One or more userIds to invalidate early access for
     */
    userId?: Array<number>;
  };
};

export type InvalidateResourceResponse = void;

export type InvalidateResourceError = ProblemDetails;

export type SubmitWorkflowData = {
  body?: WorkflowTemplate;
  query?: {
    /**
     * Whether to wait for the workflow to complete before returning or to return immediately
     * The request may return a 202 if the clients waits for the workflow to complete and the workflow does not complete within the requested timeout.
     * In which case the client should use the token to query the status of the workflow.
     */
    wait?: number;
    /**
     * Whether to actually submit the workflow or return an estimate on what would happen upon submission
     */
    whatif?: boolean;
  };
};

export type SubmitWorkflowResponse = Workflow;

export type SubmitWorkflowError = ProblemDetails;

export type QueryWorkflowsData = {
  headers?: {
    /**
     * Specify 'application/zip' to get the response as a zip file
     */
    Accept?: string;
  };
  query?: {
    /**
     * Whether to return data from oldest to newest
     */
    ascending?: boolean;
    /**
     * An optional cursor to continue querying workflows from a previous query.
     */
    cursor?: string;
    /**
     * An optional additional query that is used to match workflows through metadata
     */
    query?: string;
    /**
     * An optional list of tags to query by
     */
    tags?: Array<string>;
    /**
     * How many workflows to return
     */
    take?: number;
  };
};

export type QueryWorkflowsResponse = CursedArrayOfTelemetryCursorAndWorkflow;

export type QueryWorkflowsError = ProblemDetails;

export type GetWorkflowData = {
  path: {
    /**
     * The ID of the workflow to get status for
     */
    workflowId: string;
  };
  query?: {
    /**
     * Whether to wait for the workflow to complete before returning or to return immediately
     * The request may return a 202 if the clients waits for the workflow to complete and the workflow does not complete within the requested timeout.
     * In which case the client should use the token to query the status of the workflow.
     */
    wait?: boolean;
  };
};

export type GetWorkflowResponse = Workflow;

export type GetWorkflowError = ProblemDetails;

export type UpdateWorkflowData = {
  /**
   * The details to update on the workflow.
   */
  body?: UpdateWorkflowRequest;
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
};

export type UpdateWorkflowResponse = void;

export type UpdateWorkflowError = ProblemDetails;

export type PatchWorkflowData = {
  /**
   * A valid PATCH document
   */
  body?: JsonPatchDocument;
  path: {
    /**
     * The ID of the workflow to patch
     */
    workflowId: string;
  };
};

export type PatchWorkflowResponse = void;

export type PatchWorkflowError = ProblemDetails;

export type DeleteWorkflowData = {
  path: {
    /**
     * The ID of the workflow to delete.
     */
    workflowId: string;
  };
};

export type DeleteWorkflowResponse = void;

export type DeleteWorkflowError = ProblemDetails;

export type AddWorkflowTagData = {
  /**
   * The the tag to add to the workflow.
   */
  body?: string;
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
};

export type AddWorkflowTagResponse = void;

export type AddWorkflowTagError = ValidationProblemDetails & ProblemDetails;

export type RemoveAllWorkflowTagsData = {
  path: {
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
};

export type RemoveAllWorkflowTagsResponse = void;

export type RemoveAllWorkflowTagsError = ValidationProblemDetails & ProblemDetails;

export type RemoveWorkflowTagData = {
  path: {
    /**
     * The the tag to remove from the workflow.
     */
    tag: string;
    /**
     * The ID of the worfklow to update.
     */
    workflowId: string;
  };
};

export type RemoveWorkflowTagResponse = void;

export type RemoveWorkflowTagError = ValidationProblemDetails & ProblemDetails;

export type GetWorkflowStepData = {
  path: {
    /**
     * The name of the step within the workflow to get status for
     */
    stepName: string;
    /**
     * The id of the workflow to get status for
     */
    workflowId: string;
  };
};

export type GetWorkflowStepResponse = WorkflowStep;

export type GetWorkflowStepError = ProblemDetails;

export type UpdateWorkflowStepData = {
  /**
   * The details to update on the workflow step.
   */
  body?: UpdateWorkflowStepRequest;
  path: {
    /**
     * The name of the step to update.
     */
    stepName: string;
    /**
     * The id of the workflow to update.
     */
    workflowId: string;
  };
};

export type UpdateWorkflowStepResponse = void;

export type UpdateWorkflowStepError = ProblemDetails;

export type PatchWorkflowStepData = {
  body?: JsonPatchDocument;
  path: {
    stepName: string;
    workflowId: string;
  };
};

export type PatchWorkflowStepResponse = void;

export type PatchWorkflowStepError = ProblemDetails;

export type $OpenApiTs = {
  '/v2/consumer/blobs/{blobId}': {
    get: {
      req: GetBlobData;
      res: {
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
    head: {
      req: HeadBlobData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/ageClassification': {
    post: {
      req: InvokeAgeClassificationStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': AgeClassificationOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/comfy': {
    post: {
      req: InvokeComfyStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': ComfyOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/echo': {
    post: {
      req: InvokeEchoStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': EchoOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/imageGen': {
    post: {
      req: InvokeImageGenStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': ImageGenOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/imageResourceTraining': {
    post: {
      req: InvokeImageResourceTrainingStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': ImageResourceTrainingOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/imageUpload': {
    post: {
      req: InvokeImageUploadStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': ImageUploadOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/textToImage': {
    post: {
      req: InvokeTextToImageStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': TextToImageOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/videoEnhancement': {
    post: {
      req: InvokeVideoEnhancementStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': VideoEnhancementOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/recipes/videoGen': {
    post: {
      req: InvokeVideoGenStepTemplateData;
      res: {
        /**
         * OK
         */
        '200': VideoGenOutput;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/resources/{air}': {
    get: {
      req: GetResourceData;
      res: {
        /**
         * OK
         */
        '200': ResourceInfo;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    delete: {
      req: InvalidateResourceData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
      };
    };
  };
  '/v2/consumer/workflows': {
    post: {
      req: SubmitWorkflowData;
      res: {
        /**
         * OK
         */
        '200': Workflow;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Too Many Requests
         */
        '429': ProblemDetails;
      };
    };
    get: {
      req: QueryWorkflowsData;
      res: {
        /**
         * OK
         */
        '200': CursedArrayOfTelemetryCursorAndWorkflow;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
      };
    };
  };
  '/v2/consumer/workflows/{workflowId}': {
    get: {
      req: GetWorkflowData;
      res: {
        /**
         * OK
         */
        '200': Workflow;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    put: {
      req: UpdateWorkflowData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    patch: {
      req: PatchWorkflowData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    delete: {
      req: DeleteWorkflowData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
  };
  '/v2/consumer/workflows/{workflowId}/tags': {
    post: {
      req: AddWorkflowTagData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Bad Request
         */
        '400': ValidationProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    delete: {
      req: RemoveAllWorkflowTagsData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Bad Request
         */
        '400': ValidationProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
  };
  '/v2/consumer/workflows/{workflowId}/tags/{tag}': {
    delete: {
      req: RemoveWorkflowTagData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Bad Request
         */
        '400': ValidationProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
  };
  '/v2/consumer/workflows/{workflowId}/steps/{stepName}': {
    get: {
      req: GetWorkflowStepData;
      res: {
        /**
         * OK
         */
        '200': WorkflowStep;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    put: {
      req: UpdateWorkflowStepData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Bad Request
         */
        '400': ProblemDetails;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
    patch: {
      req: PatchWorkflowStepData;
      res: {
        /**
         * No Content
         */
        '204': void;
        /**
         * Unauthorized
         */
        '401': ProblemDetails;
        /**
         * Not Found
         */
        '404': ProblemDetails;
      };
    };
  };
};
